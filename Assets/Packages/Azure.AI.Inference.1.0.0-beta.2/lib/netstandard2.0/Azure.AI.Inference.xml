<?xml version="1.0" encoding="utf-8"?>
<doc>
    <assembly>
        <name>Azure.AI.Inference</name>
    </assembly>
    <members>
        <member name="T:Azure.AI.Inference.ChatCompletions">
            <summary>
            Representation of the response data from a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Choices">
            <summary> A list of chat completion choices. Can be more than one if `n` is greater than 1. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.FinishReason">
            <summary>
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Role">
            <summary>
            The role of the author of this message.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Content">
            <summary>
            The contents of the message.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.ToolCalls">
            <summary>
            The tool calls.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.ToString">
            <summary>
            Returns text representation of the first part of the first choice.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.#ctor(System.String,System.DateTimeOffset,System.String,Azure.AI.Inference.CompletionsUsage,System.Collections.Generic.IEnumerable{Azure.AI.Inference.ChatChoice})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletions" />. </summary>
            <param name="id"> A unique identifier associated with this chat completions response. </param>
            <param name="created">
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </param>
            <param name="model"> The model used for the chat completion. </param>
            <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
            <param name="choices">
            The collection of completions choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id" />, <paramref name="model" />, <paramref name="usage" /> or <paramref name="choices" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.#ctor(System.String,System.DateTimeOffset,System.String,Azure.AI.Inference.CompletionsUsage,System.Collections.Generic.IReadOnlyList{Azure.AI.Inference.ChatChoice},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletions" />. </summary>
            <param name="id"> A unique identifier associated with this chat completions response. </param>
            <param name="created">
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </param>
            <param name="model"> The model used for the chat completion. </param>
            <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
            <param name="choices">
            The collection of completions choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletions" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Id">
            <summary> A unique identifier associated with this chat completions response. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Created">
            <summary>
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Model">
            <summary> The model used for the chat completion. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletions.Usage">
            <summary> Usage information for tokens processed and generated as part of this completions operation. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsClient">
            <summary> The ChatCompletions service client. </summary>
            <summary> The ChatCompletions service client. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)">
            <summary> Initializes a new instance of ChatCompletionsClient. </summary>
            <param name="endpoint"> The <see cref="T:System.Uri" /> to use. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.CompleteAsync(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)">
            <summary>
            Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            </summary>
            <param name="chatCompletionsOptions">
            The configuration information for a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="chatCompletionsOptions" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.Complete(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)">
            <summary>
            Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            </summary>
            <param name="chatCompletionsOptions">
            The configuration information for a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="chatCompletionsOptions" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.CompleteStreamingAsync(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)">
            <summary>
                Begin a chat completions request and get an object that can stream response data as it becomes
                available.
            </summary>
            <param name="chatCompletionsOptions">
                the chat completions options for this chat completions request.
            </param>
            <param name="cancellationToken">
                a cancellation token that can be used to cancel the initial request or ongoing streaming operation.
            </param>
            <exception cref="T:System.ArgumentNullException">
                <paramref name="chatCompletionsOptions" /> or <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is null.
            </exception>
            <exception cref="T:System.ArgumentException">
                <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is an empty string.
            </exception>
            <returns>
            A response that, if the request was successful, may be asynchronously enumerated for
            <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> instances.
            </returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.CompleteStreaming(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)">
            <summary>
                Begin a chat completions request and get an object that can stream response data as it becomes
                available.
            </summary>
            <param name="chatCompletionsOptions">
                the chat completions options for this chat completions request.
            </param>
            <param name="cancellationToken">
                a cancellation token that can be used to cancel the initial request or ongoing streaming operation.
            </param>
            <exception cref="T:System.ArgumentNullException">
                <paramref name="chatCompletionsOptions" /> or <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is null.
            </exception>
            <exception cref="T:System.ArgumentException">
                <paramref name="chatCompletionsOptions.DeploymentName.DeploymentName" /> is an empty string.
            </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.CompleteAsync(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.CompleteAsync(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="extraParams"> The <see cref="T:System.String" /> to use. Allowed values: "error" | "drop" | "pass-through". </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.Complete(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets chat completions for the provided chat messages.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data. The method makes a REST API call to the `/chat/completions` route
            on the given endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.Complete(Azure.AI.Inference.ChatCompletionsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="extraParams"> The <see cref="T:System.String" /> to use. Allowed values: "error" | "drop" | "pass-through". </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsClient.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsClient.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.#ctor">
            <summary> Initializes a new instance of ChatCompletionsClient for mocking. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.AzureKeyCredential)">
            <summary> Initializes a new instance of ChatCompletionsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.Core.TokenCredential)">
            <summary> Initializes a new instance of ChatCompletionsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)">
            <summary> Initializes a new instance of ChatCompletionsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(System.Threading.CancellationToken)">
            <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <example>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(System.Threading.CancellationToken)">
            <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <example>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(Azure.RequestContext)">
            <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfoAsync(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(Azure.RequestContext)">
            <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.ChatCompletionsClient.GetModelInfo(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
ChatCompletionsClient client = new ChatCompletionsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsOptions">
            <summary>
            The configuration information for a chat completions request.
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.ToolChoice">
            <summary>
            If specified, the model will configure which of the provided tools it can use for the chat completions response.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.InternalShouldStreamResponse">
            <summary> A value indicating whether chat completions should be streamed for this request. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.Messages">
            <summary>
            The collection of context messages associated with this chat completions request.
            Typical usage begins with a chat message for the System role that provides instructions for
            the behavior of the assistant, followed by alternating messages between the User and
            Assistant roles.
            Please note <see cref="T:Azure.AI.Inference.ChatRequestMessage" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> and <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" />.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsOptions" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.#ctor(System.Collections.Generic.IEnumerable{Azure.AI.Inference.ChatRequestMessage})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsOptions" />. </summary>
            <param name="messages">
            The collection of context messages associated with this chat completions request.
            Typical usage begins with a chat message for the System role that provides instructions for
            the behavior of the assistant, followed by alternating messages between the User and
            Assistant roles.
            Please note <see cref="T:Azure.AI.Inference.ChatRequestMessage" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> and <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" />.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="messages" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.#ctor(System.Collections.Generic.IList{Azure.AI.Inference.ChatRequestMessage},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},Azure.AI.Inference.ChatCompletionsResponseFormat,System.Collections.Generic.IList{System.String},System.Collections.Generic.IList{Azure.AI.Inference.ChatCompletionsToolDefinition},System.BinaryData,System.Nullable{System.Int64},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsOptions" />. </summary>
            <param name="messages">
            The collection of context messages associated with this chat completions request.
            Typical usage begins with a chat message for the System role that provides instructions for
            the behavior of the assistant, followed by alternating messages between the User and
            Assistant roles.
            Please note <see cref="T:Azure.AI.Inference.ChatRequestMessage" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> and <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" />.
            </param>
            <param name="frequencyPenalty">
            A value that influences the probability of generated tokens appearing based on their cumulative
            frequency in generated text.
            Positive values will make tokens less likely to appear as their frequency increases and
            decrease the likelihood of the model repeating the same statements verbatim.
            Supported range is [-2, 2].
            </param>
            <param name="internalShouldStreamResponse"> A value indicating whether chat completions should be streamed for this request. </param>
            <param name="presencePenalty">
            A value that influences the probability of generated tokens appearing based on their existing
            presence in generated text.
            Positive values will make tokens less likely to appear when they already exist and increase the
            model's likelihood to output new topics.
            Supported range is [-2, 2].
            </param>
            <param name="temperature">
            The sampling temperature to use that controls the apparent creativity of generated completions.
            Higher values will make output more random while lower values will make results more focused
            and deterministic.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
            Supported range is [0, 1].
            </param>
            <param name="nucleusSamplingFactor">
            An alternative to sampling with temperature called nucleus sampling. This value causes the
            model to consider the results of tokens with the provided probability mass. As an example, a
            value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
            considered.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
            Supported range is [0, 1].
            </param>
            <param name="maxTokens"> The maximum number of tokens to generate. </param>
            <param name="responseFormat">
            The format that the model must output. Use this to enable JSON mode instead of the default text mode.
            Note that to enable JSON mode, some AI models may also require you to instruct the model to produce JSON
            via a system or user message.
            Please note <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormat" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON" /> and <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatText" />.
            </param>
            <param name="stopSequences"> A collection of textual sequences that will end completions generation. </param>
            <param name="tools">
            A list of tools the model may request to call. Currently, only functions are supported as a tool. The model
            may response with a function call request and provide the input arguments in JSON format for that function.
            </param>
            <param name="internalSuppressedToolChoice"> If specified, the model will configure which of the provided tools it can use for the chat completions response. </param>
            <param name="seed">
            If specified, the system will make a best effort to sample deterministically such that repeated requests with the
            same seed and parameters should return the same result. Determinism is not guaranteed.
            </param>
            <param name="model"> ID of the specific AI model to use, if more than one model is available on the endpoint. </param>
            <param name="additionalProperties"> Additional Properties. </param>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.FrequencyPenalty">
            <summary>
            A value that influences the probability of generated tokens appearing based on their cumulative
            frequency in generated text.
            Positive values will make tokens less likely to appear as their frequency increases and
            decrease the likelihood of the model repeating the same statements verbatim.
            Supported range is [-2, 2].
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.PresencePenalty">
            <summary>
            A value that influences the probability of generated tokens appearing based on their existing
            presence in generated text.
            Positive values will make tokens less likely to appear when they already exist and increase the
            model's likelihood to output new topics.
            Supported range is [-2, 2].
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.Temperature">
            <summary>
            The sampling temperature to use that controls the apparent creativity of generated completions.
            Higher values will make output more random while lower values will make results more focused
            and deterministic.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
            Supported range is [0, 1].
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.NucleusSamplingFactor">
            <summary>
            An alternative to sampling with temperature called nucleus sampling. This value causes the
            model to consider the results of tokens with the provided probability mass. As an example, a
            value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
            considered.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
            Supported range is [0, 1].
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.MaxTokens">
            <summary> The maximum number of tokens to generate. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.ResponseFormat">
            <summary>
            The format that the model must output. Use this to enable JSON mode instead of the default text mode.
            Note that to enable JSON mode, some AI models may also require you to instruct the model to produce JSON
            via a system or user message.
            Please note <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormat" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON" /> and <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatText" />.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.StopSequences">
            <summary> A collection of textual sequences that will end completions generation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.Tools">
            <summary>
            A list of tools the model may request to call. Currently, only functions are supported as a tool. The model
            may response with a function call request and provide the input arguments in JSON format for that function.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.Seed">
            <summary>
            If specified, the system will make a best effort to sample deterministically such that repeated requests with the
            same seed and parameters should return the same result. Determinism is not guaranteed.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.Model">
            <summary> ID of the specific AI model to use, if more than one model is available on the endpoint. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsOptions.AdditionalProperties">
            <summary>
            Additional Properties
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolCall">
            <summary> A function tool call requested by the AI model. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCall.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCall.Arguments">
            <summary>
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before calling
            your function.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.CreateFunctionToolCall(System.String,System.String,System.String)">
            <summary> Creates a new <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" /> representing a function call made by the model. </summary>
            <param name="toolCallId"> The ID of the tool call. </param>
            <param name="functionName"> The name of the function that model is calling. </param>
            <param name="functionArguments">
                The arguments that model is calling the function with, which are generated by the model in JSON format.
                Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before calling your function.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="toolCallId" />, <paramref name="functionName" /> or <paramref name="functionArguments" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="toolCallId" />, <paramref name="functionName" /> or <paramref name="functionArguments" /> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.#ctor(System.String,Azure.AI.Inference.FunctionCall)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="function"> The details of the function call requested by the AI model. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id" /> or <paramref name="function" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.#ctor(System.String,Azure.AI.Inference.ChatCompletionsToolCallType,Azure.AI.Inference.FunctionCall,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="type"> The type of tool call. Currently, only `function` is supported. </param>
            <param name="function"> The details of the function call requested by the AI model. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCall.Id">
            <summary> The ID of the tool call. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCall.Type">
            <summary> The type of tool call. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCall.Function">
            <summary> The details of the function call requested by the AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolChoice">
            <summary>
            Represents an optional control that specifies which, if any, tools may be called by the model while processing a
            chat completions request.
            </summary>
            <remarks>
            <list type="bullet">
            <item>
                <see cref="F:Azure.AI.Inference.ChatCompletionsToolChoice.None" /> is the default when no tools are provided and specifies that the model should not use any
                tools and instead always generate a message. Note that available tools may still influence the content of
                messages as generated by the model even when they are not or cannot be selected.
            </item>
            <item>
                <see cref="F:Azure.AI.Inference.ChatCompletionsToolChoice.Auto" /> is the default when tools are provided and specifies that the model should freely
                determine if, and which, tools should be called instead of generating a message.
            </item>
            <item>
                Providing a <see cref="T:Azure.AI.Inference.FunctionDefinition" /> or <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" /> will
                request that the model constrains its response to only calling the specified function tool.
            </item>
            </list>
            Note: with 1106 model revisions, constraining the model to a specific function via tool_choice will provide a
            finish_reason of 'stop'. Please check for 'tool_calls' rather than relying on a consistent finish_reason.
            </remarks>
        </member>
        <member name="F:Azure.AI.Inference.ChatCompletionsToolChoice.Auto">
            <summary>
            Specifies that the model may either use any of the tools provided in this chat completions request or
            instead return a standard chat completions response as if no tools were provided.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.ChatCompletionsToolChoice.None">
            <summary>
            Specifies that the model should not respond with a tool call and should instead provide a standard chat
            completions response. Response content may still be influenced by the provided tool definitions.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.ChatCompletionsToolChoice.Required">
            <summary> Specifies that the model should respond with a call to one or more tools. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoice.#ctor(Azure.AI.Inference.FunctionDefinition)">
            <summary>
            Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoice" /> that requests the model constrains its
            response to calling a provided function tool that matches the name of the provided
            <see cref="T:Azure.AI.Inference.FunctionDefinition" />.
            </summary>
            <param name="functionDefinition">
                A <see cref="T:Azure.AI.Inference.FunctionDefinition" /> with a name that matches the function tool to which model responses
                should be constrained.
            </param>
            <exception cref="T:System.ArgumentNullException">
                <paramref name="functionDefinition" /> is null.
            </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoice.#ctor(Azure.AI.Inference.ChatCompletionsToolDefinition)">
            <summary>
            Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoice" /> that requests the model constrains its
            response to calling a provided function tool definition that matches the name of the provided
            <see cref="T:Azure.AI.Inference.FunctionDefinition" />.
            </summary>
            <param name="functionToolDefinition">
                A <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" /> with a name that matches the function tool to which
                model responses should be constrained.
            </param>
            <exception cref="T:System.ArgumentNullException">
                <paramref name="functionToolDefinition" /> is null.
            </exception>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolDefinition">
            <summary> The definition of a chat completions tool that can call a function. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinition.Name">
            <summary> The name of the function to be called. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinition.Description">
            <summary>
            A description of what the function does. The model will use this description when selecting the function and
            interpreting its parameters.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinition.Parameters">
            <summary>
            The parameters the function accepts, described as a JSON Schema object.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.#ctor(Azure.AI.Inference.FunctionDefinition)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" />. </summary>
            <param name="function"> The function definition details for the function tool. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="function" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.#ctor(Azure.AI.Inference.ChatCompletionsToolDefinitionType,Azure.AI.Inference.FunctionDefinition,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" />. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function definition details for the function tool. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinition.Type">
            <summary> The type of the tool. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinition.Function">
            <summary> The function definition details for the function tool. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatMessageImageContentItem">
            <summary> A structured chat content item containing an image reference. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(System.Uri,System.Nullable{Azure.AI.Inference.ChatMessageImageDetailLevel})">
            <summary>
            Initializes a new instance of ChatMessageImageContentItem that refers to an image at another location via URL.
            </summary>
            <remarks>
            This constructor should only be used for file references. To use binary data, streams, or a file directly,
            please refer to the alternate constructors.
            </remarks>
            <param name="imageUri"> An internet location, which must be accessible to the model, from which the image may be retrieved. </param>
            <param name="detailLevel"> The image detail level the model should use when evaluating the image. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="imageUri" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(System.BinaryData,System.String,System.Nullable{Azure.AI.Inference.ChatMessageImageDetailLevel})">
            <summary>
            Initializes a new instance of ChatMessageImageContentItem from a BinaryData instance containing image
            information in a known format.
            </summary>
            <param name="bytes"> The image data to provide as content. </param>
            <param name="mimeType"> The MIME type, e.g. <c>image/png</c>, matching the format of the image data. </param>
            <param name="detailLevel"> The image detail level the model should use when evaluating the image. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(System.IO.Stream,System.String,System.Nullable{Azure.AI.Inference.ChatMessageImageDetailLevel})">
            <summary>
            Initializes a new instance of ChatMessageImageContentItem from a BinaryData instance containing image
            information in a known format.
            </summary>
            <param name="stream"> The image data to provide as content. </param>
            <param name="mimeType"> The MIME type, e.g. <c>image/png</c>, matching the format of the image data. </param>
            <param name="detailLevel"> The image detail level the model should use when evaluating the image. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(System.String,System.String,System.Nullable{Azure.AI.Inference.ChatMessageImageDetailLevel})">
            <summary>
            Initializes a new instance of ChatMessageImageContentItem from a file pointer to an image
            in a known format.
            </summary>
            <param name="imageFilePath"> The path to the image to use. </param>
            <param name="mimeType"> The MIME type, e.g. <c>image/png</c>, matching the format of the image data. </param>
            <param name="detailLevel"> The image detail level the model should use when evaluating the image. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(Azure.AI.Inference.ChatMessageImageUrl)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageContentItem" />. </summary>
            <param name="imageUrl"> An internet location, which must be accessible to the model,from which the image may be retrieved. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="imageUrl" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData},Azure.AI.Inference.ChatMessageImageUrl)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageContentItem" />. </summary>
            <param name="type"> The discriminated object type. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="imageUrl"> An internet location, which must be accessible to the model,from which the image may be retrieved. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageContentItem" /> for deserialization. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatMessageImageUrl">
            <summary> An internet location from which the model may retrieve an image. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageImageUrl.Url">
            <summary> The URL of the image. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageUrl" />. </summary>
            <param name="url"> The URL of the image. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="url" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.#ctor(System.String,System.Nullable{Azure.AI.Inference.ChatMessageImageDetailLevel},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageUrl" />. </summary>
            <param name="url"> The URL of the image. </param>
            <param name="detail">
            The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and
            accuracy.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageUrl" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageImageUrl.Detail">
            <summary>
            The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and
            accuracy.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRequestAssistantMessage">
            <summary> A request chat message representing response or action from the assistant. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.#ctor(System.String)">
            <summary>
            Creates a new instance of <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" /> that represents ordinary text content and
            does not feature tool or function calls.
            </summary>
            <param name="content"> The text content of the message. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.#ctor(System.Collections.Generic.IEnumerable{Azure.AI.Inference.ChatCompletionsToolCall},System.String)">
            <summary>
            Creates a new instance of <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" /> that represents <c>tool_calls</c> that
            were provided by the model.
            </summary>
            <param name="toolCalls"> The <c>tool_calls</c> made by the model. </param>
            <param name="content"> Optional text content associated with the message. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.#ctor(Azure.AI.Inference.ChatCompletions)">
            <summary>
            Creates a new instance of <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" /> from a <see cref="T:Azure.AI.Inference.ChatCompletions" /> with
            an <c>assistant</c> role response.
            </summary>
            <remarks>
                This constructor will copy the <c>content</c>, <c>tool_calls</c>, and <c>function_call</c> from a chat
                completion response into a new <c>assistant</c> role request message.
            </remarks>
            <param name="chatCompletions">
                The <see cref="T:Azure.AI.Inference.ChatCompletions" /> from which the conversation history request message should be created.
            </param>
            <exception cref="T:System.ArgumentException">
                The <c>role</c> of the provided chat completion response was not <see cref="P:Azure.AI.Inference.ChatRole.Assistant" />.
            </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestAssistantMessage.ParticipantName">
            <summary>
            An optional <c>name</c> associated with the assistant message. This is typically defined with a <c>system</c>
            message and is used to differentiate between multiple participants of the same role.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData},System.String,System.Collections.Generic.IList{Azure.AI.Inference.ChatCompletionsToolCall})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCalls">
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </param>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestAssistantMessage.Content">
            <summary> The content of the message. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRequestUserMessage">
            <summary> A request chat message representing user input to the assistant. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestUserMessage.Content">
            <summary>
            Gets the plain text content associated with this message. Null if the message was instantiated using a
            multimodal content item collection.
            </summary>
            <remarks>
            <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" /> may use either plain text content, which is represented by this property,
            or a collection of content items instead represented by <see cref="P:Azure.AI.Inference.ChatRequestUserMessage.MultimodalContentItems" />.
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestUserMessage.MultimodalContentItems">
            <summary>
            Gets the multimodal content item content associated with this message. Null if the message was instantiated
            using a plain text content.
            </summary>
            <remarks>
            <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" /> may use either plain text content, which is represented by
            <see cref="P:Azure.AI.Inference.ChatRequestUserMessage.Content" />, or a collection of content items instead represented by this property.
            </remarks>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.#ctor(System.String)">
            <summary>
            Creates a new instance of ChatRequestUserMessage using plain text content.
            </summary>
            <param name="content"> The plain text content associated with the message. </param>
            <exception cref="T:System.ArgumentException">
            <paramref name="content" /> is null or empty.
            </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.#ctor(System.Collections.Generic.IEnumerable{Azure.AI.Inference.ChatMessageContentItem})">
            <summary>
            Creates a new instance of ChatRequestUserMessage using a collection of structured content.
            </summary>
            <param name="content"> The collection of structured content associated with the message. </param>
            <exception cref="T:System.ArgumentException">
            <paramref name="content" /> is null or empty.
            </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.#ctor(Azure.AI.Inference.ChatMessageContentItem[])">
            <summary>
            Creates a new instance of ChatRequestUserMessage using a collection of structured content.
            </summary>
            <param name="content"> The collection of structured content associated with the message. </param>
            <exception cref="T:System.ArgumentException">
            <paramref name="content" /> is null or empty.
            </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData},System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="content"> The contents of the user message, with available input types varying by selected model. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" /> for deserialization. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingEncodingFormat">
            <summary>
            The format of the embeddings result.
            Returns a 422 error if the model doesn't support the value or parameter.
            </summary>
            <summary>
            The format of the embeddings result.
            Returns a 422 error if the model doesn't support the value or parameter.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.Single">
            <summary> Floating point. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.SByte">
            <summary> Signed 8-bit integer. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.Byte">
            <summary> Unsigned 8-bit integer. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingEncodingFormat" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.Base64">
            <summary> Base64. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.Binary">
            <summary> Binary. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingEncodingFormat.Ubinary">
            <summary> ubinary. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.op_Equality(Azure.AI.Inference.EmbeddingEncodingFormat,Azure.AI.Inference.EmbeddingEncodingFormat)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.EmbeddingEncodingFormat" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.op_Inequality(Azure.AI.Inference.EmbeddingEncodingFormat,Azure.AI.Inference.EmbeddingEncodingFormat)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.EmbeddingEncodingFormat" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.op_Implicit(System.String)~Azure.AI.Inference.EmbeddingEncodingFormat">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.EmbeddingEncodingFormat" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.Equals(Azure.AI.Inference.EmbeddingEncodingFormat)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingEncodingFormat.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingsClient">
            <summary> The Embeddings service client. </summary>
            <summary> The Embeddings service client. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)">
            <summary> Initializes a new instance of EmbeddingsClient. </summary>
            <param name="endpoint"> The <see cref="T:System.Uri" /> to use. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)">
            <summary>
            Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            </summary>
            <param name="embeddingsOptions" />
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embeddingsOptions" /> is null. </exception>
            <example>
This sample shows how to call EmbedAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = await client.EmbedAsync(embeddingsOptions);
]]></code>
This sample shows how to call EmbedAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = await client.EmbedAsync(embeddingsOptions);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)">
            <summary>
            Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            </summary>
            <param name="embeddingsOptions" />
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embeddingsOptions" /> is null. </exception>
            <example>
This sample shows how to call Embed.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = client.Embed(embeddingsOptions);
]]></code>
This sample shows how to call Embed.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

EmbeddingsOptions embeddingsOptions = null;
Response<EmbeddingsResult> response = client.Embed(embeddingsOptions);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.EmbedAsync(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="extraParams">
            Controls what happens if extra parameters, undefined by the REST API,
            are passed in the JSON request payload.
            This sets the HTTP request header `extra-parameters`. Allowed values: "error" | "drop" | "pass-through"
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Return the embedding vectors for given text prompts.
            The method makes a REST API call to the `/embeddings` route on the given endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.Embed(Azure.AI.Inference.EmbeddingsOptions,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="extraParams">
            Controls what happens if extra parameters, undefined by the REST API,
            are passed in the JSON request payload.
            This sets the HTTP request header `extra-parameters`. Allowed values: "error" | "drop" | "pass-through"
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsClient.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsClient.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.#ctor">
            <summary> Initializes a new instance of EmbeddingsClient for mocking. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.AzureKeyCredential)">
            <summary> Initializes a new instance of EmbeddingsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.Core.TokenCredential)">
            <summary> Initializes a new instance of EmbeddingsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Inference.AzureAIInferenceClientOptions)">
            <summary> Initializes a new instance of EmbeddingsClient. </summary>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(System.Threading.CancellationToken)">
            <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <example>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code>
This sample shows how to call GetModelInfoAsync.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = await client.GetModelInfoAsync();
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(System.Threading.CancellationToken)">
            <summary>
            Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <example>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code>
This sample shows how to call GetModelInfo.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response<ModelInfo> response = client.GetModelInfo();
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(Azure.RequestContext)">
            <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfoAsync(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfoAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = await client.GetModelInfoAsync(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(Azure.RequestContext)">
            <summary>
            [Protocol Method] Returns information about the AI model.
            The method makes a REST API call to the `/info` route on the given endpoint.
            This method will only work when using Serverless API or Managed Compute endpoint.
            It will not work for GitHub Models endpoint or Azure OpenAI endpoint.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Inference.EmbeddingsClient.GetModelInfo(System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code>
This sample shows how to call GetModelInfo and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<endpoint>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
EmbeddingsClient client = new EmbeddingsClient(endpoint, credential);

Response response = client.GetModelInfo(null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("model_name").ToString());
Console.WriteLine(result.GetProperty("model_type").ToString());
Console.WriteLine(result.GetProperty("model_provider_name").ToString());
]]></code></example>
        </member>
        <member name="T:Azure.AI.Inference.FunctionCall">
            <summary> The name and arguments of a function that should be called, as generated by the model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of FunctionCall. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before calling
            your function.
            </param>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.FunctionCall" />. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before calling
            your function.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.FunctionCall" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.FunctionCall.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="P:Azure.AI.Inference.FunctionCall.Arguments">
            <summary>
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before calling
            your function.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.FunctionDefinition">
            <summary> The definition of a caller-specified function that chat completions may invoke in response to matching user input. </summary>
        </member>
        <member name="F:Azure.AI.Inference.FunctionDefinition.Auto">
            <summary>
            Specifies that the model may either use any of the tools provided in this chat completions request or
            instead return a standard chat completions response as if no tools were provided.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.FunctionDefinition.None">
            <summary>
            Specifies that the model should not respond with a tool call and should instead provide a standard chat
            completions response. Response content may still be influenced by the provided tool definitions.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.FunctionDefinition.Required">
            <summary> Specifies that the model should respond with a call to one or more tools. </summary>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.#ctor">
            <summary>
            Initializes a new instance of FunctionDefinition.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.FunctionDefinition.Name">
            <summary> The name of the function to be called. </summary>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.FunctionDefinition" />. </summary>
            <param name="name"> The name of the function to be called. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.#ctor(System.String,System.String,System.BinaryData,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.FunctionDefinition" />. </summary>
            <param name="name"> The name of the function to be called. </param>
            <param name="description">
            A description of what the function does. The model will use this description when selecting the function and
            interpreting its parameters.
            </param>
            <param name="parameters"> The parameters the function accepts, described as a JSON Schema object. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Inference.FunctionDefinition.Description">
            <summary>
            A description of what the function does. The model will use this description when selecting the function and
            interpreting its parameters.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.FunctionDefinition.Parameters">
            <summary>
            The parameters the function accepts, described as a JSON Schema object.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.StreamingChatChoiceUpdate">
            <summary>
            Represents an update to a single prompt completion when the service is streaming updates
            using Server Sent Events (SSE).
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </summary>
            <summary>
            Represents an update to a single prompt completion when the service is streaming updates
            using Server Sent Events (SSE).
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatChoiceUpdate.Delta">
            <summary> An update to the chat message for a given chat completions prompt. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.#ctor(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.StreamingChatResponseMessageUpdate)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatChoiceUpdate" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="delta"> An update to the chat message for a given chat completions prompt. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="delta" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.#ctor(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.StreamingChatResponseMessageUpdate,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatChoiceUpdate" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="delta"> An update to the chat message for a given chat completions prompt. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatChoiceUpdate" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatChoiceUpdate.Index">
            <summary> The ordered index associated with this chat completions choice. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatChoiceUpdate.FinishReason">
            <summary> The reason that this chat completions choice completed its generated. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.StreamingChatCompletionsUpdate">
            <summary>
            Represents an incremental update to a streamed Chat Completions response.
            </summary>
            <summary>
            Represents a response update to a chat completions request, when the service is streaming updates
            using Server Sent Events (SSE).
            Completions support a wide variety of tasks and generate text that continues from or "completes"
            provided prompt data.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Id">
            <summary>
            Gets a unique identifier associated with this streamed Chat Completions response.
            </summary>
            <remarks>
            <para>
            Corresponds to $.id in the underlying REST schema.
            </para>
            When using Azure OpenAI, note that the values of <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Id" /> and <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Created" /> may not be
            populated until the first <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> containing role, content, or
            function information.
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Model">
            <summary> The model used for the chat completion. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Created">
            <summary>
            Gets the first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </summary>
            <remarks>
            <para>
            Corresponds to $.created in the underlying REST schema.
            </para>
            When using Azure OpenAI, note that the values of <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Id" /> and <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Created" /> may not be
            populated until the first <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> containing role, content, or
            function information.
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Role">
            <summary>
            Gets the <see cref="T:Azure.AI.Inference.ChatRole" /> associated with this update.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.role in the underlying REST schema.
            </para>
            <see cref="T:Azure.AI.Inference.ChatRole" /> assignment typically occurs in a single update across a streamed Chat Completions
            choice and the value should be considered to be persist for all subsequent updates without a
            <see cref="T:Azure.AI.Inference.ChatRole" /> that bear the same index.
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.ContentUpdate">
            <summary>
            Gets the content fragment associated with this update.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.content in the underlying REST schema.
            </para>
            Each update contains only a small number of tokens. When presenting or reconstituting a full, streamed
            response, all <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.ContentUpdate" /> values for the same index should be combined.
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.ToolCallUpdate">
            <summary>
            An incremental update payload for a tool call that is part of this response.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.tool_calls[0] in the REST API schema.
            </para>
            <para>
            To differentiate between parallel streaming tool calls within a single streaming choice, use the value of the
            <see cref="P:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.Id" /> property.
            </para>
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.FinishReason">
            <summary>
            Gets the <see cref="T:Azure.AI.Inference.CompletionsFinishReason" /> associated with this update.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].finish_reason in the underlying REST schema.
            </para>
            <para>
            <see cref="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.FinishReason" /> assignment typically appears in the final streamed update message associated
            with a choice.
            </para>
            </remarks>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.#ctor(System.String,System.DateTimeOffset,System.String,Azure.AI.Inference.CompletionsUsage,System.Collections.Generic.IEnumerable{Azure.AI.Inference.StreamingChatChoiceUpdate})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" />. </summary>
            <param name="id"> A unique identifier associated with this chat completions response. </param>
            <param name="created">
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </param>
            <param name="model"> The model used for the chat completion. </param>
            <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
            <param name="choices">
            An update to the collection of completion choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id" />, <paramref name="model" />, <paramref name="usage" /> or <paramref name="choices" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.#ctor(System.String,System.DateTimeOffset,System.String,Azure.AI.Inference.CompletionsUsage,System.Collections.Generic.IReadOnlyList{Azure.AI.Inference.StreamingChatChoiceUpdate},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" />. </summary>
            <param name="id"> A unique identifier associated with this chat completions response. </param>
            <param name="created">
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </param>
            <param name="model"> The model used for the chat completion. </param>
            <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
            <param name="choices">
            An update to the collection of completion choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Usage">
            <summary> Usage information for tokens processed and generated as part of this completions operation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatCompletionsUpdate.Choices">
            <summary>
            An update to the collection of completion choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.StreamingChatResponseMessageUpdate">
            <summary> A representation of a chat message update as received in a streaming response. </summary>
            <summary> A representation of a chat message update as received in a streaming response. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatResponseMessageUpdate.ToolCalls">
            <summary>
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseMessageUpdate" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.#ctor(System.Nullable{Azure.AI.Inference.ChatRole},System.String,System.Collections.Generic.IReadOnlyList{Azure.AI.Inference.StreamingChatResponseToolCallUpdate},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseMessageUpdate" />. </summary>
            <param name="role"> The chat role associated with the message. If present, should always be 'assistant'. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCalls">
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatResponseMessageUpdate.Role">
            <summary> The chat role associated with the message. If present, should always be 'assistant'. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatResponseMessageUpdate.Content">
            <summary> The content of the message. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.StreamingFunctionToolCallUpdate">
            <summary>
            Represents an incremental update to a streaming function tool call that is part of a streaming chat completions
            choice.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingFunctionToolCallUpdate.Name">
            <summary>
            The name of the function requested by the tool call.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.tool_calls[0].function.name in the REST API schema.
            </para>
            <para>
            For a streaming function tool call, this name will appear in a single streaming update payload, typically the
            first. Use the <see cref="P:Azure.AI.Inference.StreamingToolCallUpdate.ToolCallIndex" /> property to differentiate between multiple,
            parallel tool calls when streaming.
            </para>
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingFunctionToolCallUpdate.ArgumentsUpdate">
            <summary>
            The next new segment of the function arguments for the function tool called by a streaming tool call.
            These must be accumulated for the complete contents of the function arguments.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.tool_calls[0].function.arguments in the REST API schema.
            </para>
            Note that the model does not always generate valid JSON and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before calling
            your function.
            </remarks>
        </member>
        <member name="T:Azure.AI.Inference.StreamingToolCallUpdate">
            <summary>
            Represents an incremental update to a streaming tool call that is part of a streaming chat completions choice.
            </summary>
            <remarks>
            <para>
            This type encapsulates the payload located in e.g. $.choices[0].delta.tool_calls[] in the REST API schema.
            </para>
            <para>
            To differentiate between parallel streaming tool calls within a single streaming choice, use the value of the
            <see cref="P:Azure.AI.Inference.StreamingToolCallUpdate.ToolCallIndex" /> property.
            </para>
            <para>
            Please note <see cref="T:Azure.AI.Inference.StreamingToolCallUpdate" /> is the base class. According to the scenario, a derived class
            of the base class might need to be assigned here, or this property needs to be casted to one of the possible
            derived classes.
            The available derived classes include: <see cref="T:Azure.AI.Inference.StreamingFunctionToolCallUpdate" />.
            </para>
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingToolCallUpdate.Id">
            <summary>
            Gets the ID associated with with the streaming tool call.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.tool_calls[0].id in the REST API schema.
            </para>
            <para>
            This value appears once for each streaming tool call, typically on the first update message for each
            <see cref="P:Azure.AI.Inference.StreamingToolCallUpdate.ToolCallIndex" />. Callers should retain the value when it arrives to accumulate the complete tool
            call information.
            </para>
            <para>
            Tool call IDs must be provided in <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> instances that respond to tool calls.
            </para>
            </remarks>
        </member>
        <member name="P:Azure.AI.Inference.StreamingToolCallUpdate.ToolCallIndex">
            <summary>
            Gets the tool call index associated with this <see cref="T:Azure.AI.Inference.StreamingToolCallUpdate" />.
            </summary>
            <remarks>
            <para>
            Corresponds to e.g. $.choices[0].delta.tool_calls[0].index in the REST API schema.
            </para>
            <para>
            This value appears on every streaming tool call update. When multiple tool calls occur within the same
            streaming chat choice, this index specifies which tool call that this update contains new information for.
            </para>
            </remarks>
        </member>
        <member name="T:Azure.AI.Inference.AIInferenceModelFactory">
            <summary> Model factory for models. </summary>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatRequestSystemMessage(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />. </summary>
            <param name="content"> The contents of the system message. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatMessageTextContentItem(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" />. </summary>
            <param name="text"> The content of the message. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatCompletionsToolCall(System.String,Azure.AI.Inference.ChatCompletionsToolCallType,Azure.AI.Inference.FunctionCall)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="type"> The type of tool call. Currently, only `function` is supported. </param>
            <param name="function"> The details of the function call requested by the AI model. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatCompletionsToolCall" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatRequestToolMessage(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" />. </summary>
            <param name="content"> The content of the message. </param>
            <param name="toolCallId"> The ID of the tool call resolved by the provided content. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatCompletionsToolDefinition(Azure.AI.Inference.ChatCompletionsToolDefinitionType,Azure.AI.Inference.FunctionDefinition)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" />. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function definition details for the function tool. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinition" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatCompletionsNamedToolChoice(Azure.AI.Inference.ChatCompletionsNamedToolChoiceType,Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice" />. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function that should be called. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.CompletionsUsage(System.Int32,System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompletionsUsage" />. </summary>
            <param name="completionTokens"> The number of tokens generated across all completions emissions. </param>
            <param name="promptTokens"> The number of tokens in the provided prompts for the completions request. </param>
            <param name="totalTokens"> The total number of tokens processed for the completions request and response. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.CompletionsUsage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatChoice(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.ChatResponseMessage)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatChoice" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="message"> The chat message for a given chat completions prompt. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatChoice" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ChatResponseMessage(Azure.AI.Inference.ChatRole,System.String,System.Collections.Generic.IEnumerable{Azure.AI.Inference.ChatCompletionsToolCall})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatResponseMessage" />. </summary>
            <param name="role"> The chat role associated with the message. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCalls">
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ChatResponseMessage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.ModelInfo(System.String,Azure.AI.Inference.ModelType,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ModelInfo" />. </summary>
            <param name="modelName"> The name of the AI model. For example: `Phi21`. </param>
            <param name="modelType"> The type of the AI model. A Unique identifier for the profile. </param>
            <param name="modelProviderName"> The model provider name. For example: `Microsoft Research`. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.ModelInfo" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.EmbeddingsResult(System.String,System.Collections.Generic.IEnumerable{Azure.AI.Inference.EmbeddingItem},Azure.AI.Inference.EmbeddingsUsage,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsResult" />. </summary>
            <param name="id"> Unique identifier for the embeddings result. </param>
            <param name="data"> Embedding values for the prompts submitted in the request. </param>
            <param name="usage"> Usage counts for tokens input using the embeddings API. </param>
            <param name="model"> The model ID used to generate this result. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.EmbeddingsResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.EmbeddingItem(System.BinaryData,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingItem" />. </summary>
            <param name="embedding">
            List of embedding values for the input prompt. These represent a measurement of the
            vector-based relatedness of the provided input. Or a base64 encoded string of the embedding vector.
            </param>
            <param name="index"> Index of the prompt to which the EmbeddingItem corresponds. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.EmbeddingItem" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.EmbeddingsUsage(System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsUsage" />. </summary>
            <param name="promptTokens"> Number of tokens in the request. </param>
            <param name="totalTokens">
            Total number of tokens transacted in this request/response. Should equal the
            number of tokens in the request.
            </param>
            <returns> A new <see cref="T:Azure.AI.Inference.EmbeddingsUsage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.StreamingChatCompletionsUpdate(System.String,System.DateTimeOffset,System.String,Azure.AI.Inference.CompletionsUsage,System.Collections.Generic.IEnumerable{Azure.AI.Inference.StreamingChatChoiceUpdate})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" />. </summary>
            <param name="id"> A unique identifier associated with this chat completions response. </param>
            <param name="created">
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
            </param>
            <param name="model"> The model used for the chat completion. </param>
            <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
            <param name="choices">
            An update to the collection of completion choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </param>
            <returns> A new <see cref="T:Azure.AI.Inference.StreamingChatCompletionsUpdate" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.StreamingChatChoiceUpdate(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.StreamingChatResponseMessageUpdate)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatChoiceUpdate" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="delta"> An update to the chat message for a given chat completions prompt. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.StreamingChatChoiceUpdate" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.StreamingChatResponseMessageUpdate(System.Nullable{Azure.AI.Inference.ChatRole},System.String,System.Collections.Generic.IEnumerable{Azure.AI.Inference.StreamingChatResponseToolCallUpdate})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseMessageUpdate" />. </summary>
            <param name="role"> The chat role associated with the message. If present, should always be 'assistant'. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCalls">
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </param>
            <returns> A new <see cref="T:Azure.AI.Inference.StreamingChatResponseMessageUpdate" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Inference.AIInferenceModelFactory.StreamingChatResponseToolCallUpdate(System.String,Azure.AI.Inference.FunctionCall)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="function"> Updates to the function call requested by the AI model. </param>
            <returns> A new <see cref="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate" /> instance for mocking. </returns>
        </member>
        <member name="T:Azure.AI.Inference.AzureAIInferenceClientOptions">
            <summary> Client options for Azure.AI.Inference library clients. </summary>
        </member>
        <member name="T:Azure.AI.Inference.AzureAIInferenceClientOptions.ServiceVersion">
            <summary> The version of the service to use. </summary>
        </member>
        <member name="F:Azure.AI.Inference.AzureAIInferenceClientOptions.ServiceVersion.V2024_05_01_Preview">
            <summary> Service version "2024-05-01-preview". </summary>
        </member>
        <member name="M:Azure.AI.Inference.AzureAIInferenceClientOptions.#ctor(Azure.AI.Inference.AzureAIInferenceClientOptions.ServiceVersion)">
            <summary> Initializes new instance of AzureAIInferenceClientOptions. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatChoice">
            <summary>
            The representation of a single prompt completion as part of an overall chat completions request.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.#ctor(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.ChatResponseMessage)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatChoice" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="message"> The chat message for a given chat completions prompt. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="message" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.#ctor(System.Int32,System.Nullable{Azure.AI.Inference.CompletionsFinishReason},Azure.AI.Inference.ChatResponseMessage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatChoice" />. </summary>
            <param name="index"> The ordered index associated with this chat completions choice. </param>
            <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
            <param name="message"> The chat message for a given chat completions prompt. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatChoice" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatChoice.Index">
            <summary> The ordered index associated with this chat completions choice. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatChoice.FinishReason">
            <summary> The reason that this chat completions choice completed its generated. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatChoice.Message">
            <summary> The chat message for a given chat completions prompt. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice">
            <summary> A tool selection of a specific, named function tool that will limit chat completions to using the named function. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.#ctor(Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice" />. </summary>
            <param name="function"> The function that should be called. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="function" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.#ctor(Azure.AI.Inference.ChatCompletionsNamedToolChoiceType,Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice" />. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function that should be called. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoice" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsNamedToolChoice.Type">
            <summary> The type of the tool. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsNamedToolChoice.Function">
            <summary> The function that should be called. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction">
            <summary> A tool selection of a specific, named function tool that will limit chat completions to using the named function. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction" />. </summary>
            <param name="name"> The name of the function that should be called. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction" />. </summary>
            <param name="name"> The name of the function that should be called. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.Name">
            <summary> The name of the function that should be called. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType">
            <summary> The ChatCompletionsNamedToolChoice_type. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.op_Equality(Azure.AI.Inference.ChatCompletionsNamedToolChoiceType,Azure.AI.Inference.ChatCompletionsNamedToolChoiceType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.op_Inequality(Azure.AI.Inference.ChatCompletionsNamedToolChoiceType,Azure.AI.Inference.ChatCompletionsNamedToolChoiceType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.op_Implicit(System.String)~Azure.AI.Inference.ChatCompletionsNamedToolChoiceType">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.Equals(Azure.AI.Inference.ChatCompletionsNamedToolChoiceType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsResponseFormat">
            <summary>
            Represents the format that the model must output. Use this to enable JSON mode instead of the default text mode.
            Note that to enable JSON mode, some AI models may also require you to instruct the model to produce JSON
            via a system or user message.
            Please note <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormat" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON" /> and <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatText" />.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.ChatCompletionsResponseFormat._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormat" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormat" />. </summary>
            <param name="type"> The response format type to use for chat completions. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsResponseFormat.Type">
            <summary> The response format type to use for chat completions. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON">
            <summary>
            A response format for Chat Completions that restricts responses to emitting valid JSON objects.
            Note that to enable JSON mode, some AI models may also require you to instruct the model to produce JSON
            via a system or user message.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatJSON" />. </summary>
            <param name="type"> The response format type to use for chat completions. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsResponseFormatText">
            <summary> A response format for Chat Completions that emits text responses. This is the default response format. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatText" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsResponseFormatText" />. </summary>
            <param name="type"> The response format type to use for chat completions. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolCallType">
            <summary> The ChatCompletionsToolCall_type. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolCallType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolCallType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.op_Equality(Azure.AI.Inference.ChatCompletionsToolCallType,Azure.AI.Inference.ChatCompletionsToolCallType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolCallType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.op_Inequality(Azure.AI.Inference.ChatCompletionsToolCallType,Azure.AI.Inference.ChatCompletionsToolCallType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolCallType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.op_Implicit(System.String)~Azure.AI.Inference.ChatCompletionsToolCallType">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatCompletionsToolCallType" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.Equals(Azure.AI.Inference.ChatCompletionsToolCallType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCallType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolChoicePreset">
            <summary> Represents a generic policy for how a chat completions tool may be selected. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoicePreset" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolChoicePreset.Auto">
            <summary>
            Specifies that the model may either use any of the tools provided in this chat completions request or
            instead return a standard chat completions response as if no tools were provided.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolChoicePreset.None">
            <summary>
            Specifies that the model should not respond with a tool call and should instead provide a standard chat
            completions response. Response content may still be influenced by the provided tool definitions.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolChoicePreset.Required">
            <summary> Specifies that the model should respond with a call to one or more tools. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.op_Equality(Azure.AI.Inference.ChatCompletionsToolChoicePreset,Azure.AI.Inference.ChatCompletionsToolChoicePreset)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoicePreset" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.op_Inequality(Azure.AI.Inference.ChatCompletionsToolChoicePreset,Azure.AI.Inference.ChatCompletionsToolChoicePreset)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoicePreset" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.op_Implicit(System.String)~Azure.AI.Inference.ChatCompletionsToolChoicePreset">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatCompletionsToolChoicePreset" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.Equals(Azure.AI.Inference.ChatCompletionsToolChoicePreset)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolChoicePreset.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ChatCompletionsToolDefinitionType">
            <summary> The ChatCompletionsToolDefinition_type. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinitionType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatCompletionsToolDefinitionType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.op_Equality(Azure.AI.Inference.ChatCompletionsToolDefinitionType,Azure.AI.Inference.ChatCompletionsToolDefinitionType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinitionType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.op_Inequality(Azure.AI.Inference.ChatCompletionsToolDefinitionType,Azure.AI.Inference.ChatCompletionsToolDefinitionType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinitionType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.op_Implicit(System.String)~Azure.AI.Inference.ChatCompletionsToolDefinitionType">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatCompletionsToolDefinitionType" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.Equals(Azure.AI.Inference.ChatCompletionsToolDefinitionType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinitionType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ChatMessageContentItem">
            <summary>
            An abstract representation of a structured content item within a chat message.
            Please note <see cref="T:Azure.AI.Inference.ChatMessageContentItem" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatMessageImageContentItem" /> and <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" />.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.ChatMessageContentItem._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageContentItem" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageContentItem" />. </summary>
            <param name="type"> The discriminated object type. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageContentItem.Type">
            <summary> The discriminated object type. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatMessageImageDetailLevel">
            <summary> A representation of the possible image detail levels for image-based chat completions message content. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageImageDetailLevel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageImageDetailLevel.Auto">
            <summary> Specifies that the model should determine which detail level to apply using heuristics like image size. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageImageDetailLevel.Low">
            <summary>
            Specifies that image evaluation should be constrained to the 'low-res' model that may be faster and consume fewer
            tokens but may also be less accurate for highly detailed images.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageImageDetailLevel.High">
            <summary>
            Specifies that image evaluation should enable the 'high-res' model that may be more accurate for highly detailed
            images but may also be slower and consume more tokens.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.op_Equality(Azure.AI.Inference.ChatMessageImageDetailLevel,Azure.AI.Inference.ChatMessageImageDetailLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatMessageImageDetailLevel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.op_Inequality(Azure.AI.Inference.ChatMessageImageDetailLevel,Azure.AI.Inference.ChatMessageImageDetailLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatMessageImageDetailLevel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.op_Implicit(System.String)~Azure.AI.Inference.ChatMessageImageDetailLevel">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatMessageImageDetailLevel" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.Equals(Azure.AI.Inference.ChatMessageImageDetailLevel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageDetailLevel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ChatMessageTextContentItem">
            <summary> A structured chat content item containing plain text. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" />. </summary>
            <param name="text"> The content of the message. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="text" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData},System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" />. </summary>
            <param name="type"> The discriminated object type. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="text"> The content of the message. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatMessageTextContentItem" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatMessageTextContentItem.Text">
            <summary> The content of the message. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRequestMessage">
            <summary>
            An abstract representation of a chat message as provided in a request.
            Please note <see cref="T:Azure.AI.Inference.ChatRequestMessage" /> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
            The available derived classes include <see cref="T:Azure.AI.Inference.ChatRequestAssistantMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />, <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> and <see cref="T:Azure.AI.Inference.ChatRequestUserMessage" />.
            </summary>
        </member>
        <member name="F:Azure.AI.Inference.ChatRequestMessage._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestMessage" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestMessage.Role">
            <summary> The chat role associated with this message. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRequestSystemMessage">
            <summary>
            A request chat message containing system instructions that influence how the model will generate a chat completions
            response.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />. </summary>
            <param name="content"> The contents of the system message. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData},System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="content"> The contents of the system message. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestSystemMessage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestSystemMessage.Content">
            <summary> The contents of the system message. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRequestToolMessage">
            <summary> A request chat message representing requested output from a configured tool. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" />. </summary>
            <param name="content"> The content of the message. </param>
            <param name="toolCallId"> The ID of the tool call resolved by the provided content. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="toolCallId" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData},System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCallId"> The ID of the tool call resolved by the provided content. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRequestToolMessage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestToolMessage.Content">
            <summary> The content of the message. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRequestToolMessage.ToolCallId">
            <summary> The ID of the tool call resolved by the provided content. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatResponseMessage">
            <summary> A representation of a chat message as received in a response. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.#ctor(Azure.AI.Inference.ChatRole,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatResponseMessage" />. </summary>
            <param name="role"> The chat role associated with the message. </param>
            <param name="content"> The content of the message. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.#ctor(Azure.AI.Inference.ChatRole,System.String,System.Collections.Generic.IReadOnlyList{Azure.AI.Inference.ChatCompletionsToolCall},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatResponseMessage" />. </summary>
            <param name="role"> The chat role associated with the message. </param>
            <param name="content"> The content of the message. </param>
            <param name="toolCalls">
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatResponseMessage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatResponseMessage.Role">
            <summary> The chat role associated with the message. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatResponseMessage.Content">
            <summary> The content of the message. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatResponseMessage.ToolCalls">
            <summary>
            The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
            completions request to resolve as configured.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ChatRole">
            <summary> A description of the intended purpose of a message within a chat completions interaction. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ChatRole" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ChatRole.System">
            <summary> The role that instructs or sets the behavior of the assistant. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRole.User">
            <summary> The role that provides input for chat completions. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRole.Assistant">
            <summary> The role that provides responses to system-instructed, user-prompted input. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ChatRole.Tool">
            <summary> The role that represents extension tool activity within a chat completions operation. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.op_Equality(Azure.AI.Inference.ChatRole,Azure.AI.Inference.ChatRole)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatRole" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.op_Inequality(Azure.AI.Inference.ChatRole,Azure.AI.Inference.ChatRole)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ChatRole" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.op_Implicit(System.String)~Azure.AI.Inference.ChatRole">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ChatRole" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.Equals(Azure.AI.Inference.ChatRole)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRole.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.CompleteRequest">
            <summary> The CompleteRequest. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.#ctor(Azure.AI.Inference.ChatCompletionsOptions)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompleteRequest" />. </summary>
            <param name="chatCompletionsOptions"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="chatCompletionsOptions" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.#ctor(Azure.AI.Inference.ChatCompletionsOptions,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompleteRequest" />. </summary>
            <param name="chatCompletionsOptions"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompleteRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompleteRequest.ChatCompletionsOptions">
            <summary> Gets the chat completions options. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.CompletionsFinishReason">
            <summary> Representation of the manner in which a completions response concluded. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompletionsFinishReason" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsFinishReason.Stopped">
            <summary> Completions ended normally and reached its end of token generation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsFinishReason.TokenLimitReached">
            <summary> Completions exhausted available token limits before generation could complete. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsFinishReason.ContentFiltered">
            <summary>
            Completions generated a response that was identified as potentially sensitive per content
            moderation policies.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsFinishReason.ToolCalls">
            <summary> Completion ended with the model calling a provided tool for output. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.op_Equality(Azure.AI.Inference.CompletionsFinishReason,Azure.AI.Inference.CompletionsFinishReason)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.CompletionsFinishReason" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.op_Inequality(Azure.AI.Inference.CompletionsFinishReason,Azure.AI.Inference.CompletionsFinishReason)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.CompletionsFinishReason" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.op_Implicit(System.String)~Azure.AI.Inference.CompletionsFinishReason">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.CompletionsFinishReason" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.Equals(Azure.AI.Inference.CompletionsFinishReason)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsFinishReason.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.CompletionsUsage">
            <summary>
            Representation of the token counts processed for a completions request.
            Counts consider all tokens across prompts, choices, choice alternates, best_of generations, and
            other consumers.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompletionsUsage" />. </summary>
            <param name="completionTokens"> The number of tokens generated across all completions emissions. </param>
            <param name="promptTokens"> The number of tokens in the provided prompts for the completions request. </param>
            <param name="totalTokens"> The total number of tokens processed for the completions request and response. </param>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.#ctor(System.Int32,System.Int32,System.Int32,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompletionsUsage" />. </summary>
            <param name="completionTokens"> The number of tokens generated across all completions emissions. </param>
            <param name="promptTokens"> The number of tokens in the provided prompts for the completions request. </param>
            <param name="totalTokens"> The total number of tokens processed for the completions request and response. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.CompletionsUsage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsUsage.CompletionTokens">
            <summary> The number of tokens generated across all completions emissions. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsUsage.PromptTokens">
            <summary> The number of tokens in the provided prompts for the completions request. </summary>
        </member>
        <member name="P:Azure.AI.Inference.CompletionsUsage.TotalTokens">
            <summary> The total number of tokens processed for the completions request and response. </summary>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingInputType">
            <summary> Represents the input types used for embedding search. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingInputType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingInputType.Text">
            <summary> Indicates the input is a general text input. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingInputType.Query">
            <summary> Indicates the input represents a search query to find the most relevant documents in your vector database. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingInputType.Document">
            <summary> Indicates the input represents a document that is stored in a vector database. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.op_Equality(Azure.AI.Inference.EmbeddingInputType,Azure.AI.Inference.EmbeddingInputType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.EmbeddingInputType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.op_Inequality(Azure.AI.Inference.EmbeddingInputType,Azure.AI.Inference.EmbeddingInputType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.EmbeddingInputType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.op_Implicit(System.String)~Azure.AI.Inference.EmbeddingInputType">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.EmbeddingInputType" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.Equals(Azure.AI.Inference.EmbeddingInputType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingInputType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingItem">
            <summary> Representation of a single embeddings relatedness comparison. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.#ctor(System.BinaryData,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingItem" />. </summary>
            <param name="embedding">
            List of embedding values for the input prompt. These represent a measurement of the
            vector-based relatedness of the provided input. Or a base64 encoded string of the embedding vector.
            </param>
            <param name="index"> Index of the prompt to which the EmbeddingItem corresponds. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embedding" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.#ctor(System.BinaryData,System.Int32,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingItem" />. </summary>
            <param name="embedding">
            List of embedding values for the input prompt. These represent a measurement of the
            vector-based relatedness of the provided input. Or a base64 encoded string of the embedding vector.
            </param>
            <param name="index"> Index of the prompt to which the EmbeddingItem corresponds. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingItem" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingItem.Embedding">
            <summary>
            List of embedding values for the input prompt. These represent a measurement of the
            vector-based relatedness of the provided input. Or a base64 encoded string of the embedding vector.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.String" /></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1" /> where <c>T</c> is of type <see cref="T:System.Single" /></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingItem.Index">
            <summary> Index of the prompt to which the EmbeddingItem corresponds. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingsOptions">
            <summary> The configuration information for an embeddings request. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.#ctor(System.Collections.Generic.IEnumerable{System.String})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsOptions" />. </summary>
            <param name="input">
            Input text to embed, encoded as a string or array of tokens.
            To embed multiple inputs in a single request, pass an array
            of strings or array of token arrays.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="input" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.#ctor(System.Collections.Generic.IList{System.String},System.Nullable{System.Int32},System.Nullable{Azure.AI.Inference.EmbeddingEncodingFormat},System.Nullable{Azure.AI.Inference.EmbeddingInputType},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsOptions" />. </summary>
            <param name="input">
            Input text to embed, encoded as a string or array of tokens.
            To embed multiple inputs in a single request, pass an array
            of strings or array of token arrays.
            </param>
            <param name="dimensions">
            Optional. The number of dimensions the resulting output embeddings should have.
            Passing null causes the model to use its default value.
            Returns a 422 error if the model doesn't support the value or parameter.
            </param>
            <param name="encodingFormat"> Optional. The desired format for the returned embeddings. </param>
            <param name="inputType">
            Optional. The type of the input.
            Returns a 422 error if the model doesn't support the value or parameter.
            </param>
            <param name="model"> ID of the specific AI model to use, if more than one model is available on the endpoint. </param>
            <param name="additionalProperties"> Additional Properties. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsOptions" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.Input">
            <summary>
            Input text to embed, encoded as a string or array of tokens.
            To embed multiple inputs in a single request, pass an array
            of strings or array of token arrays.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.Dimensions">
            <summary>
            Optional. The number of dimensions the resulting output embeddings should have.
            Passing null causes the model to use its default value.
            Returns a 422 error if the model doesn't support the value or parameter.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.EncodingFormat">
            <summary> Optional. The desired format for the returned embeddings. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.InputType">
            <summary>
            Optional. The type of the input.
            Returns a 422 error if the model doesn't support the value or parameter.
            </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.Model">
            <summary> ID of the specific AI model to use, if more than one model is available on the endpoint. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsOptions.AdditionalProperties">
            <summary>
            Additional Properties
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingsResult">
            <summary>
            Representation of the response data from an embeddings request.
            Embeddings measure the relatedness of text strings and are commonly used for search, clustering,
            recommendations, and other similar scenarios.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.#ctor(System.String,System.Collections.Generic.IEnumerable{Azure.AI.Inference.EmbeddingItem},Azure.AI.Inference.EmbeddingsUsage,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsResult" />. </summary>
            <param name="id"> Unique identifier for the embeddings result. </param>
            <param name="data"> Embedding values for the prompts submitted in the request. </param>
            <param name="usage"> Usage counts for tokens input using the embeddings API. </param>
            <param name="model"> The model ID used to generate this result. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id" />, <paramref name="data" />, <paramref name="usage" /> or <paramref name="model" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.#ctor(System.String,System.Collections.Generic.IReadOnlyList{Azure.AI.Inference.EmbeddingItem},Azure.AI.Inference.EmbeddingsUsage,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsResult" />. </summary>
            <param name="id"> Unique identifier for the embeddings result. </param>
            <param name="data"> Embedding values for the prompts submitted in the request. </param>
            <param name="usage"> Usage counts for tokens input using the embeddings API. </param>
            <param name="model"> The model ID used to generate this result. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsResult.Id">
            <summary> Unique identifier for the embeddings result. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsResult.Data">
            <summary> Embedding values for the prompts submitted in the request. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsResult.Usage">
            <summary> Usage counts for tokens input using the embeddings API. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsResult.Model">
            <summary> The model ID used to generate this result. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbeddingsUsage">
            <summary> Measurement of the amount of tokens used in this request and response. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.#ctor(System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsUsage" />. </summary>
            <param name="promptTokens"> Number of tokens in the request. </param>
            <param name="totalTokens">
            Total number of tokens transacted in this request/response. Should equal the
            number of tokens in the request.
            </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.#ctor(System.Int32,System.Int32,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsUsage" />. </summary>
            <param name="promptTokens"> Number of tokens in the request. </param>
            <param name="totalTokens">
            Total number of tokens transacted in this request/response. Should equal the
            number of tokens in the request.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbeddingsUsage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsUsage.PromptTokens">
            <summary> Number of tokens in the request. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbeddingsUsage.TotalTokens">
            <summary>
            Total number of tokens transacted in this request/response. Should equal the
            number of tokens in the request.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.EmbedRequest">
            <summary> The EmbedRequest. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.#ctor(Azure.AI.Inference.EmbeddingsOptions)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbedRequest" />. </summary>
            <param name="embeddingsOptions"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embeddingsOptions" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.#ctor(Azure.AI.Inference.EmbeddingsOptions,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbedRequest" />. </summary>
            <param name="embeddingsOptions"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.EmbedRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.EmbedRequest.EmbeddingsOptions">
            <summary> Gets the embeddings options. </summary>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ExtraParameters">
            <summary> Controls what happens if extra parameters, undefined by the REST API, are passed in the JSON request payload. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ExtraParameters" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ExtraParameters.Error">
            <summary> The service will error if it detected extra parameters in the request payload. This is the service default. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ExtraParameters.Drop">
            <summary> The service will ignore (drop) extra parameters in the request payload. It will only pass the known parameters to the back-end AI model. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ExtraParameters.PassThrough">
            <summary> The service will pass extra parameters to the back-end AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.op_Equality(Azure.AI.Inference.ExtraParameters,Azure.AI.Inference.ExtraParameters)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ExtraParameters" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.op_Inequality(Azure.AI.Inference.ExtraParameters,Azure.AI.Inference.ExtraParameters)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ExtraParameters" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.op_Implicit(System.String)~Azure.AI.Inference.ExtraParameters">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ExtraParameters" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.Equals(Azure.AI.Inference.ExtraParameters)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ExtraParameters.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.ModelInfo">
            <summary> Represents some basic information about the AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.#ctor(System.String,Azure.AI.Inference.ModelType,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ModelInfo" />. </summary>
            <param name="modelName"> The name of the AI model. For example: `Phi21`. </param>
            <param name="modelType"> The type of the AI model. A Unique identifier for the profile. </param>
            <param name="modelProviderName"> The model provider name. For example: `Microsoft Research`. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="modelName" /> or <paramref name="modelProviderName" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.#ctor(System.String,Azure.AI.Inference.ModelType,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ModelInfo" />. </summary>
            <param name="modelName"> The name of the AI model. For example: `Phi21`. </param>
            <param name="modelType"> The type of the AI model. A Unique identifier for the profile. </param>
            <param name="modelProviderName"> The model provider name. For example: `Microsoft Research`. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ModelInfo" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelInfo.ModelName">
            <summary> The name of the AI model. For example: `Phi21`. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelInfo.ModelType">
            <summary> The type of the AI model. A Unique identifier for the profile. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelInfo.ModelProviderName">
            <summary> The model provider name. For example: `Microsoft Research`. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.ModelType">
            <summary> The type of AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.ModelType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.Embeddings">
            <summary> Embeddings. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.ImageGeneration">
            <summary> Image generation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.TextGeneration">
            <summary> Text generation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.ImageEmbeddings">
            <summary> Image embeddings. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.AudioGeneration">
            <summary> Audio generation. </summary>
        </member>
        <member name="P:Azure.AI.Inference.ModelType.Chat">
            <summary> Chat completions. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.op_Equality(Azure.AI.Inference.ModelType,Azure.AI.Inference.ModelType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ModelType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.op_Inequality(Azure.AI.Inference.ModelType,Azure.AI.Inference.ModelType)">
            <summary> Determines if two <see cref="T:Azure.AI.Inference.ModelType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.op_Implicit(System.String)~Azure.AI.Inference.ModelType">
            <summary> Converts a <see cref="T:System.String" /> to a <see cref="T:Azure.AI.Inference.ModelType" />. </summary>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.Equals(Azure.AI.Inference.ModelType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ModelType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate">
            <summary> An update to the function tool call information requested by the AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.#ctor(System.String,Azure.AI.Inference.FunctionCall)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="function"> Updates to the function call requested by the AI model. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id" /> or <paramref name="function" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.#ctor(System.String,Azure.AI.Inference.FunctionCall,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate" />. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="function"> Updates to the function call requested by the AI model. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.StreamingChatResponseToolCallUpdate" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.Id">
            <summary> The ID of the tool call. </summary>
        </member>
        <member name="P:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.Function">
            <summary> Updates to the function call requested by the AI model. </summary>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.UnknownChatCompletionsResponseFormat">
            <summary> Unknown version of ChatCompletionsResponseFormat. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatCompletionsResponseFormat" />. </summary>
            <param name="type"> The response format type to use for chat completions. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatCompletionsResponseFormat" /> for deserialization. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.UnknownChatMessageContentItem">
            <summary> Unknown version of ChatMessageContentItem. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatMessageContentItem" />. </summary>
            <param name="type"> The discriminated object type. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatMessageContentItem" /> for deserialization. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.UnknownChatRequestMessage">
            <summary> Unknown version of ChatRequestMessage. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.#ctor(Azure.AI.Inference.ChatRole,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatRequestMessage" />. </summary>
            <param name="role"> The chat role associated with this message. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Inference.UnknownChatRequestMessage" /> for deserialization. </summary>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Inference.StreamingResponse`1">
            <summary>
            Represents an operation response with streaming content that can be deserialized and enumerated while the response
            is still being received.
            </summary>
            <typeparam name="T"> The data type representative of distinct, streamable items. </typeparam>
        </member>
        <member name="M:Azure.AI.Inference.StreamingResponse`1.CreateFromResponse(Azure.Response,System.Func{Azure.Response,System.Collections.Generic.IAsyncEnumerable{`0}})">
            <summary>
            Creates a new instance of <see cref="T:Azure.AI.Inference.StreamingResponse`1" /> using the provided underlying HTTP response. The
            provided function will be used to resolve the response into an asynchronous enumeration of streamed response
            items.
            </summary>
            <param name="response">The HTTP response.</param>
            <param name="asyncEnumerableProcessor">
            The function that will resolve the provided response into an IAsyncEnumerable.
            </param>
            <returns>
            A new instance of <see cref="T:Azure.AI.Inference.StreamingResponse`1" /> that will be capable of asynchronous enumeration of
            <typeparamref name="T" /> items from the HTTP response.
            </returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingResponse`1.GetRawResponse">
            <summary>
            Gets the underlying <see cref="T:Azure.Response" /> instance that this <see cref="T:Azure.AI.Inference.StreamingResponse`1" /> may enumerate
            over.
            </summary>
            <returns> The <see cref="T:Azure.Response" /> instance attached to this <see cref="T:Azure.AI.Inference.StreamingResponse`1" />. </returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingResponse`1.EnumerateValues">
            <summary>
            Gets the asynchronously enumerable collection of distinct, streamable items in the response.
            </summary>
            <remarks>
            <para> The return value of this method may be used with the "await foreach" statement. </para>
            <para>
            As <see cref="T:Azure.AI.Inference.StreamingResponse`1" /> explicitly implements <see cref="T:System.Collections.Generic.IAsyncEnumerable`1" />, callers may
            enumerate a <see cref="T:Azure.AI.Inference.StreamingResponse`1" /> instance directly instead of calling this method.
            </para>
            </remarks>
            <returns></returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingResponse`1.Dispose">
            <summary>Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.</summary>
        </member>
        <member name="M:Azure.AI.Inference.Telemetry.OpenTelemetryScope.Start(Azure.AI.Inference.ChatCompletionsOptions,System.Uri)">
            <summary>
            Create the instance of OpenTelemetryScope. This constructor logs request
            and starts the execution timer.
            </summary>
            <param name="requestOptions">The request options used in the call.</param>
            <param name="endpoint">The endpoint being called.</param>
        </member>
        <member name="M:Azure.AI.Inference.Telemetry.OpenTelemetryScope.RecordError(System.Exception)">
            <summary>
            Log the error.
            </summary>
            <param name="e">Exception thrown by completion call.</param>
        </member>
        <member name="M:Azure.AI.Inference.Telemetry.OpenTelemetryScope.RecordCancellation">
            <summary>
            Record the task cancellation event.
            </summary>
        </member>
        <member name="T:Azure.Core.ArrayBufferWriter`1">
            <summary>
            Represents a heap-based, array-backed output sink into which <typeparam name="T" /> data can be written.
            </summary>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.#ctor">
            <summary>
            Creates an instance of an <see cref="T:Azure.Core.ArrayBufferWriter`1" />, in which data can be written to,
            with the default initial capacity.
            </summary>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.#ctor(System.Int32)">
            <summary>
            Creates an instance of an <see cref="T:Azure.Core.ArrayBufferWriter`1" />, in which data can be written to,
            with an initial capacity specified.
            </summary>
            <param name="initialCapacity">The minimum capacity with which to initialize the underlying buffer.</param>
            <exception cref="T:System.ArgumentException">
            Thrown when <paramref name="initialCapacity" /> is not positive (i.e. less than or equal to 0).
            </exception>
        </member>
        <member name="P:Azure.Core.ArrayBufferWriter`1.WrittenMemory">
            <summary>
            Returns the data written to the underlying buffer so far, as a <see cref="T:System.ReadOnlyMemory`1" />.
            </summary>
        </member>
        <member name="P:Azure.Core.ArrayBufferWriter`1.WrittenSpan">
            <summary>
            Returns the data written to the underlying buffer so far, as a <see cref="T:System.ReadOnlySpan`1" />.
            </summary>
        </member>
        <member name="P:Azure.Core.ArrayBufferWriter`1.WrittenCount">
            <summary>
            Returns the amount of data written to the underlying buffer so far.
            </summary>
        </member>
        <member name="P:Azure.Core.ArrayBufferWriter`1.Capacity">
            <summary>
            Returns the total amount of space within the underlying buffer.
            </summary>
        </member>
        <member name="P:Azure.Core.ArrayBufferWriter`1.FreeCapacity">
            <summary>
            Returns the amount of space available that can still be written into without forcing the underlying buffer to grow.
            </summary>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.Clear">
            <summary>
            Clears the data written to the underlying buffer.
            </summary>
            <remarks>
            You must clear the <see cref="T:Azure.Core.ArrayBufferWriter`1" /> before trying to re-use it.
            </remarks>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.Advance(System.Int32)">
            <summary>
            Notifies <see cref="T:System.Buffers.IBufferWriter`1" /> that <paramref name="count" /> amount of data was written to the output <see cref="T:System.Span`1" />/<see cref="T:System.Memory`1" />.
            </summary>
            <exception cref="T:System.ArgumentException">
            Thrown when <paramref name="count" /> is negative.
            </exception>
            <exception cref="T:System.InvalidOperationException">
            Thrown when attempting to advance past the end of the underlying buffer.
            </exception>
            <remarks>
            You must request a new buffer after calling Advance to continue writing more data and cannot write to a previously acquired buffer.
            </remarks>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.GetMemory(System.Int32)">
            <summary>
            Returns a <see cref="T:System.Memory`1" /> to write to that is at least the requested length (specified by <paramref name="sizeHint" />).
            If no <paramref name="sizeHint" /> is provided (or it's equal to <code>0</code>), some non-empty buffer is returned.
            </summary>
            <exception cref="T:System.ArgumentException">
            Thrown when <paramref name="sizeHint" /> is negative.
            </exception>
            <remarks>
            This will never return an empty <see cref="T:System.Memory`1" />.
            </remarks>
            <remarks>
            There is no guarantee that successive calls will return the same buffer or the same-sized buffer.
            </remarks>
            <remarks>
            You must request a new buffer after calling Advance to continue writing more data and cannot write to a previously acquired buffer.
            </remarks>
        </member>
        <member name="M:Azure.Core.ArrayBufferWriter`1.GetSpan(System.Int32)">
            <summary>
            Returns a <see cref="T:System.Span`1" /> to write to that is at least the requested length (specified by <paramref name="sizeHint" />).
            If no <paramref name="sizeHint" /> is provided (or it's equal to <code>0</code>), some non-empty buffer is returned.
            </summary>
            <exception cref="T:System.ArgumentException">
            Thrown when <paramref name="sizeHint" /> is negative.
            </exception>
            <remarks>
            This will never return an empty <see cref="T:System.Span`1" />.
            </remarks>
            <remarks>
            There is no guarantee that successive calls will return the same buffer or the same-sized buffer.
            </remarks>
            <remarks>
            You must request a new buffer after calling Advance to continue writing more data and cannot write to a previously acquired buffer.
            </remarks>
        </member>
        <member name="T:Azure.Core.AzureResourceProviderNamespaceAttribute">
            <summary>
            This attribute should be set on all client assemblies with value of one of the resource providers
            from the https://docs.microsoft.com/azure/azure-resource-manager/management/azure-services-resource-providers list.
            </summary>
        </member>
        <member name="M:Azure.Core.AzureKeyCredentialPolicy.#ctor(Azure.AzureKeyCredential,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.AzureKeyCredentialPolicy" /> class.
            </summary>
            <param name="credential">The <see cref="T:Azure.AzureKeyCredential" /> used to authenticate requests.</param>
            <param name="name">The name of the key header used for the credential.</param>
            <param name="prefix">The prefix to apply before the credential key. For example, a prefix of "SharedAccessKey" would result in
            a value of "SharedAccessKey {credential.Key}" being stamped on the request header with header key of <paramref name="name" />.</param>
        </member>
        <member name="M:Azure.Core.AzureKeyCredentialPolicy.OnSendingRequest(Azure.Core.HttpMessage)">
            <summary>
            Method is invoked before the request is sent.
            </summary><param name="message">The <see cref="T:Azure.Core.HttpMessage" /> containing the request.</param>
        </member>
        <member name="P:Azure.Core.CodeGenModelAttribute.Usage">
            <summary>
            Gets or sets a coma separated list of additional model usage modes. Allowed values: model, error, intput, output.
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenModelAttribute.Formats">
            <summary>
            Gets or sets a coma separated list of additional model serialization formats.
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.PropertyName">
            <summary>
            Gets or sets the property name which these hooks should apply to
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.SerializationPath">
            <summary>
            Gets or sets the serialization path of the property in the JSON
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.SerializationValueHook">
            <summary>
            Gets or sets the method name to use when serializing the property value (property name excluded)
            The signature of the serialization hook method must be or compatible with when invoking:
            private void SerializeHook(Utf8JsonWriter writer);
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.DeserializationValueHook">
            <summary>
            Gets or sets the method name to use when deserializing the property value from the JSON
            private static void DeserializationHook(JsonProperty property, ref TypeOfTheProperty propertyValue); // if the property is required
            private static void DeserializationHook(JsonProperty property, ref Optional&lt;TypeOfTheProperty&gt; propertyValue); // if the property is optional
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.BicepSerializationValueHook">
            <summary>
            Gets or sets the method name to use when serializing the property value (property name excluded)
            The signature of the serialization hook method must be or compatible with when invoking:
            private void SerializeHook(StringBuilder builder);
            </summary>
        </member>
        <member name="T:Azure.Core.AppContextSwitchHelper">
            <summary>
            Helper for interacting with AppConfig settings and their related Environment variable settings.
            </summary>
        </member>
        <member name="M:Azure.Core.AppContextSwitchHelper.GetConfigValue(System.String,System.String)">
            <summary>
            Determines if either an AppContext switch or its corresponding Environment Variable is set
            </summary>
            <param name="appContexSwitchName">Name of the AppContext switch.</param>
            <param name="environmentVariableName">Name of the Environment variable.</param>
            <returns>If the AppContext switch has been set, returns the value of the switch.
            If the AppContext switch has not been set, returns the value of the environment variable.
            False if neither is set.
            </returns>
        </member>
        <member name="T:Azure.Core.AsyncLockWithValue`1">
            <summary>
            Primitive that combines async lock and value cache
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="M:Azure.Core.AsyncLockWithValue`1.GetLockOrValueAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Method that either returns cached value or acquire a lock.
            If one caller has acquired a lock, other callers will be waiting for the lock to be released.
            If value is set, lock is released and all waiters get that value.
            If value isn't set, the next waiter in the queue will get the lock.
            </summary>
            <param name="async"></param>
            <param name="cancellationToken"></param>
            <returns></returns>
        </member>
        <member name="P:Azure.Core.AsyncLockWithValue`1.LockOrValue.HasValue">
            <summary>
            Returns true if lock contains the cached value. Otherwise false.
            </summary>
        </member>
        <member name="P:Azure.Core.AsyncLockWithValue`1.LockOrValue.Value">
            <summary>
            Returns cached value if it was set when lock has been created. Throws exception otherwise.
            </summary>
            <exception cref="T:System.InvalidOperationException">Value isn't set.</exception>
        </member>
        <member name="M:Azure.Core.AsyncLockWithValue`1.LockOrValue.SetValue(`0)">
            <summary>
            Set value to the cache and to all the waiters.
            </summary>
            <param name="value"></param>
            <exception cref="T:System.InvalidOperationException">Value is set already.</exception>
        </member>
        <member name="M:Azure.Core.Pipeline.ClientDiagnostics.#ctor(Azure.Core.ClientOptions,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> class.
            </summary>
            <param name="options">The customer provided client options object.</param>
            <param name="suppressNestedClientActivities">Flag controlling if <see cref="T:System.Diagnostics.Activity" />
             created by this <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> for client method calls should be suppressed when called
             by other Azure SDK client methods.  It's recommended to set it to true for new clients; use default (null)
             for backward compatibility reasons, or set it to false to explicitly disable suppression for specific cases.
             The default value could change in the future, the flag should be only set to false if suppression for the client
             should never be enabled.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.ClientDiagnostics.#ctor(System.String,System.String,Azure.Core.DiagnosticsOptions,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> class.
            </summary>
            <param name="optionsNamespace">Namespace of the client class, such as Azure.Storage or Azure.AppConfiguration.</param>
            <param name="providerNamespace">Azure Resource Provider namespace of the Azure service SDK is primarily used for.</param>
            <param name="diagnosticsOptions">The customer provided client diagnostics options.</param>
            <param name="suppressNestedClientActivities">Flag controlling if <see cref="T:System.Diagnostics.Activity" />
             created by this <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> for client method calls should be suppressed when called
             by other Azure SDK client methods.  It's recommended to set it to true for new clients, use default (null) for old clients
             for backward compatibility reasons, or set it to false to explicitly disable suppression for specific cases.
             The default value could change in the future, the flag should be only set to false if suppression for the client
             should never be enabled.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.AddLink(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.Object})">
            <summary>
            Adds a link to the scope. This must be called before <see cref="M:Azure.Core.Pipeline.DiagnosticScope.Start" /> has been called for the DiagnosticScope.
            </summary>
            <param name="traceparent">The traceparent for the link.</param>
            <param name="tracestate">The tracestate for the link.</param>
            <param name="attributes">Optional attributes to associate with the link.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.SetTraceContext(System.String,System.String)">
            <summary>
            Sets the trace context for the current scope.
            </summary>
            <param name="traceparent">The trace parent to set for the current scope.</param>
            <param name="tracestate">The trace state to set for the current scope.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.Failed(System.Exception)">
            <summary>
            Marks the scope as failed.
            </summary>
            <param name="exception">The exception to associate with the failed scope.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.Failed(System.String)">
            <summary>
            Marks the scope as failed with low-cardinality error.type attribute.
            </summary>
            <param name="errorCode">Error code to associate with the failed scope.</param>
        </member>
        <member name="T:Azure.Core.Pipeline.ActivityExtensions">
            <summary>
            Until Activity Source is no longer considered experimental.
            </summary>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScopeFactory.#ctor(System.String,System.String,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Creates diagnostic scope factory.
            </summary>
            <param name="clientNamespace">The namespace which is used as a prefix for all ActivitySources created by the factory and the name of DiagnosticSource (when used).</param>
            <param name="resourceProviderNamespace">Azure resource provider namespace.</param>
            <param name="isActivityEnabled">Flag indicating if distributed tracing is enabled.</param>
            <param name="suppressNestedClientActivities">Flag indicating if nested Azure SDK activities describing public API calls should be suppressed.</param>
            <param name="isStable">Whether instrumentation is considered stable. When false, experimental feature flag controls if tracing is enabled.</param>
        </member>
        <member name="T:Azure.Core.Pipeline.TaskExtensions.Enumerable`1">
            <summary>
            Both <see cref="T:Azure.Core.Pipeline.TaskExtensions.Enumerable`1" /> and <see cref="T:Azure.Core.Pipeline.TaskExtensions.Enumerator`1" /> are defined as public structs so that foreach can use duck typing
            to call <see cref="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.GetEnumerator" /> and avoid heap memory allocation.
            Please don't delete this method and don't make these types private.
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="T:Azure.Core.FixedDelayWithNoJitterStrategy">
            <summary>
            A delay strategy that uses a fixed delay with no jitter applied. This is used by data plane LROs.
            </summary>
        </member>
        <member name="T:Azure.Core.OperationInternal">
            <summary>
            A helper class used to build long-running operation instances. In order to use this helper:
            <list type="number">
              <item>Make sure your LRO implements the <see cref="T:Azure.Core.IOperation" /> interface.</item>
              <item>Add a private <see cref="T:Azure.Core.OperationInternal" /> field to your LRO, and instantiate it during construction.</item>
              <item>Delegate method calls to the <see cref="T:Azure.Core.OperationInternal" /> implementations.</item>
            </list>
            Supported members:
            <list type="bullet">
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.HasCompleted" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.RawResponse" />, used for <see cref="M:Azure.Operation.GetRawResponse" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.TimeSpan,System.Threading.CancellationToken)" /></description>
              </item>
            </list>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationInternal.Succeeded(Azure.Response)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final successful state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal.Failed(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final failed state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="operationFailedException">The exception that will be thrown by <c>UpdateStatusAsync</c>.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal.#ctor(Azure.Core.IOperation,Azure.Core.Pipeline.ClientDiagnostics,Azure.Response,System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Azure.Core.DelayStrategy)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class.
            </summary>
            <param name="operation">The long-running operation making use of this class. Passing "<c>this</c>" is expected.</param>
            <param name="clientDiagnostics">Used for diagnostic scope and exception creation. This is expected to be the instance created during the construction of your main client.</param>
            <param name="rawResponse">
                The initial value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />. Usually, long-running operation objects can be instantiated in two ways:
                <list type="bullet">
                    <item>
                        When calling a client's "<c>Start&lt;OperationName&gt;</c>" method, a service call is made to start the operation, and an <see cref="T:Azure.Operation" /> instance is returned.
                        In this case, the response received from this service call can be passed here.
                    </item>
                    <item>
                        When a user instantiates an <see cref="T:Azure.Operation" /> directly using a public constructor, there's no previous service call. In this case, passing <c>null</c> is expected.
                    </item>
                </list>
            </param>
            <param name="operationTypeName">
                The type name of the long-running operation making use of this class. Used when creating diagnostic scopes. If left <c>null</c>, the type name will be inferred based on the
                parameter <paramref name="operation" />.
            </param>
            <param name="scopeAttributes">The attributes to use during diagnostic scope creation.</param>
            <param name="fallbackStrategy"> The delay strategy to use. Default is <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />.</param>
        </member>
        <member name="T:Azure.Core.IOperation">
            <summary>
            An interface used by <see cref="T:Azure.Core.OperationInternal" /> for making service calls and updating state. It's expected that
            your long-running operation classes implement this interface.
            </summary>
        </member>
        <member name="M:Azure.Core.IOperation.UpdateStateAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Calls the service and updates the state of the long-running operation. Properties directly handled by the
            <see cref="T:Azure.Core.OperationInternal" /> class, such as <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />
            don't need to be updated. Operation-specific properties, such as "<c>CreateOn</c>" or "<c>LastModified</c>",
            must be manually updated by the operation implementing this method.
            <example>Usage example:
            <code>
              async ValueTask&lt;OperationState&gt; IOperation.UpdateStateAsync(bool async, CancellationToken cancellationToken)<br />
              {<br />
                Response&lt;R&gt; response = async ? &lt;async service call&gt; : &lt;sync service call&gt;;<br />
                if (&lt;operation succeeded&gt;) return OperationState.Success(response.GetRawResponse(), &lt;parse response&gt;);<br />
                if (&lt;operation failed&gt;) return OperationState.Failure(response.GetRawResponse());<br />
                return OperationState.Pending(response.GetRawResponse());<br />
              }
            </code>
            </example>
            </summary>
            <param name="async"><c>true</c> if the call should be executed asynchronously. Otherwise, <c>false</c>.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>
            A structure indicating the current operation state. The <see cref="T:Azure.Core.OperationState" /> structure must be instantiated by one of
            its static methods:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState.Success(Azure.Response)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </returns>
        </member>
        <member name="T:Azure.Core.OperationState">
            <summary>
            A helper structure passed to <see cref="T:Azure.Core.OperationInternal" /> to indicate the current operation state. This structure must be
            instantiated by one of its static methods, depending on the operation state:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState.Success(Azure.Response)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationState.Success(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has completed successfully.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has completed with failures.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="operationFailedException">
            The exception to throw from <c>UpdateStatus</c> because of the operation failure. If left <c>null</c>,
            a default exception is created based on the <paramref name="rawResponse" /> parameter.
            </param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState.Pending(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has not completed yet.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="P:Azure.Core.OperationInternalBase.RawResponse">
            <summary>
            The last HTTP response received from the server. Its update already handled in calls to "<c>UpdateStatus</c>" and
            "<c>WaitForCompletionAsync</c>", but custom methods not supported by this class, such as "<c>CancelOperation</c>",
            must update it as well.
            <example>Usage example:
            <code>
              public Response GetRawResponse() =&gt; _operationInternal.RawResponse;
            </code>
            </example>
            </summary>
        </member>
        <member name="P:Azure.Core.OperationInternalBase.HasCompleted">
            <summary>
            Returns <c>true</c> if the long-running operation has completed.
            <example>Usage example:
            <code>
              public bool HasCompleted =&gt; _operationInternal.HasCompleted;
            </code>
            </example>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get the latest status of the long-running operation, handling diagnostic scope creation for distributed
            tracing. The default scope name can be changed with the "<c>operationTypeName</c>" parameter passed to the constructor.
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&gt; UpdateStatusAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.UpdateStatusAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The HTTP response received from the server.</returns>
            <remarks>
            After a successful run, this method will update <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> and might update <see cref="P:Azure.Core.OperationInternalBase.HasCompleted" />.
            </remarks>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get the latest status of the long-running operation, handling diagnostic scope creation for distributed
            tracing. The default scope name can be changed with the "<c>operationTypeName</c>" parameter passed to the constructor.
            <example>Usage example:
            <code>
              public Response UpdateStatus(CancellationToken cancellationToken) =&gt; _operationInternal.UpdateStatus(cancellationToken);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The HTTP response received from the server.</returns>
            <remarks>
            After a successful run, this method will update <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> and might update <see cref="P:Azure.Core.OperationInternalBase.HasCompleted" />.
            </remarks>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.  The maximum of the retry after value and the fallback strategy
            is then used as the wait interval.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server. <strong></strong></param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponse(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.  The maximum of the retry after value and the fallback strategy
            is then used as the wait interval.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponse(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="T:Azure.Core.OperationInternal`1">
            <summary>
            A helper class used to build long-running operation instances. In order to use this helper:
            <list type="number">
              <item>Make sure your LRO implements the <see cref="T:Azure.Core.IOperation`1" /> interface.</item>
              <item>Add a private <see cref="T:Azure.Core.OperationInternal`1" /> field to your LRO, and instantiate it during construction.</item>
              <item>Delegate method calls to the <see cref="T:Azure.Core.OperationInternal`1" /> implementations.</item>
            </list>
            Supported members:
            <list type="bullet">
              <item>
                <description><see cref="P:Azure.Core.OperationInternal`1.HasValue" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.HasCompleted" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternal`1.Value" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.RawResponse" />, used for <see cref="M:Azure.Operation.GetRawResponse" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)" /></description>
              </item>
            </list>
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.Succeeded(Azure.Response,`0)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final successful state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="value">The final result of the long-running operation.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.Failed(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final failed state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="operationFailedException">The exception that will be thrown by <c>UpdateStatusAsync</c>.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.#ctor(Azure.Core.IOperation{`0},Azure.Core.Pipeline.ClientDiagnostics,Azure.Response,System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Azure.Core.DelayStrategy)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal`1" /> class.
            </summary>
            <param name="operation">The long-running operation making use of this class. Passing "<c>this</c>" is expected.</param>
            <param name="clientDiagnostics">Used for diagnostic scope and exception creation. This is expected to be the instance created during the construction of your main client.</param>
            <param name="rawResponse">
                The initial value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />. Usually, long-running operation objects can be instantiated in two ways:
                <list type="bullet">
                    <item>
                        When calling a client's "<c>Start&lt;OperationName&gt;</c>" method, a service call is made to start the operation, and an <see cref="T:Azure.Operation`1" /> instance is returned.
                        In this case, the response received from this service call can be passed here.
                    </item>
                    <item>
                        When a user instantiates an <see cref="T:Azure.Operation`1" /> directly using a public constructor, there's no previous service call. In this case, passing <c>null</c> is expected.
                    </item>
                </list>
            </param>
            <param name="operationTypeName">
                The type name of the long-running operation making use of this class. Used when creating diagnostic scopes. If left <c>null</c>, the type name will be inferred based on the
                parameter <paramref name="operation" />.
            </param>
            <param name="scopeAttributes">The attributes to use during diagnostic scope creation.</param>
            <param name="fallbackStrategy">The delay strategy when Retry-After header is not present.  When it is present, the longer of the two delays will be used.
                Default is <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />.</param>
        </member>
        <member name="P:Azure.Core.OperationInternal`1.HasValue">
            <summary>
            Returns <c>true</c> if the long-running operation completed successfully and has produced a final result.
            <example>Usage example:
            <code>
              public bool HasValue =&gt; _operationInternal.HasValue;
            </code>
            </example>
            </summary>
        </member>
        <member name="P:Azure.Core.OperationInternal`1.Value">
            <summary>
            The final result of the long-running operation.
            <example>Usage example:
            <code>
              public T Value =&gt; _operationInternal.Value;
            </code>
            </example>
            </summary>
            <exception cref="T:System.InvalidOperationException">Thrown when the operation has not completed yet.</exception>
            <exception cref="T:Azure.RequestFailedException">Thrown when the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletion(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletion(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />, which takes into account any retry-after header that is returned
            from the server.
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="T:Azure.Core.IOperation`1">
            <summary>
            An interface used by <see cref="T:Azure.Core.OperationInternal`1" /> for making service calls and updating state. It's expected that
            your long-running operation classes implement this interface.
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.IOperation`1.UpdateStateAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Calls the service and updates the state of the long-running operation. Properties directly handled by the
            <see cref="T:Azure.Core.OperationInternal`1" /> class, such as <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> or
            <see cref="P:Azure.Core.OperationInternal`1.Value" />, don't need to be updated. Operation-specific properties, such
            as "<c>CreateOn</c>" or "<c>LastModified</c>", must be manually updated by the operation implementing this
            method.
            <example>Usage example:
            <code>
              async ValueTask&lt;OperationState&lt;T&gt;&gt; IOperation&lt;T&gt;.UpdateStateAsync(bool async, CancellationToken cancellationToken)<br />
              {<br />
                Response&lt;R&gt; response = async ? &lt;async service call&gt; : &lt;sync service call&gt;;<br />
                if (&lt;operation succeeded&gt;) return OperationState&lt;T&gt;.Success(response.GetRawResponse(), &lt;parse response&gt;);<br />
                if (&lt;operation failed&gt;) return OperationState&lt;T&gt;.Failure(response.GetRawResponse());<br />
                return OperationState&lt;T&gt;.Pending(response.GetRawResponse());<br />
              }
            </code>
            </example>
            </summary>
            <param name="async"><c>true</c> if the call should be executed asynchronously. Otherwise, <c>false</c>.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>
            A structure indicating the current operation state. The <see cref="T:Azure.Core.OperationState`1" /> structure must be instantiated by one of
            its static methods:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </returns>
        </member>
        <member name="T:Azure.Core.OperationState`1">
            <summary>
            A helper structure passed to <see cref="T:Azure.Core.OperationInternal`1" /> to indicate the current operation state. This structure must be
            instantiated by one of its static methods, depending on the operation state:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has completed successfully.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="value">The final result of the long-running operation.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> or <paramref name="value" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has completed with failures.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="operationFailedException">
            The exception to throw from <c>UpdateStatus</c> because of the operation failure. The same exception will be thrown when
            <see cref="P:Azure.Core.OperationInternal`1.Value" /> is called. If left <c>null</c>, a default exception is created based on the
            <paramref name="rawResponse" /> parameter.
            </param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState`1.Pending(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has not completed yet.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="T:Azure.Core.OperationPoller">
            <summary>
            Implementation of LRO polling logic.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.Id">
            <summary>
            Gets an ID representing the operation that can be used to poll for
            the status of the long-running operation.
            There are cases that operation id is not available, we return "NOT_SET" for unavailable operation id.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.Value">
            <summary>
            Final result of the long-running operation.
            </summary><remarks>
            This property can be accessed only after the operation completes successfully (HasValue is true).
            </remarks>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.HasCompleted">
            <summary>
            Returns true if the long-running operation completed.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.HasValue">
            <summary>
            Returns true if the long-running operation completed successfully and has produced final result (accessible by Value property).
            </summary>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.GetRawResponse">
            <summary>
            The last HTTP response received from the server.
            </summary><remarks>
            The last response returned from the server during the lifecycle of this instance.
            An instance of <see cref="T:Azure.Operation`1" /> sends requests to a server in UpdateStatusAsync, UpdateStatus, and other methods.
            Responses from these requests can be accessed using GetRawResponse.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.UpdateStatus(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get updated status of the long-running operation.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the service call.</param><returns>The HTTP response received from the server.</returns><remarks>
            This operation will update the value returned from GetRawResponse and might update HasCompleted.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.UpdateStatusAsync(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get updated status of the long-running operation.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the service call.</param><returns>The HTTP response received from the server.</returns><remarks>
            This operation will update the value returned from GetRawResponse and might update HasCompleted.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.WaitForCompletionAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls the server till the long-running operation completes.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the periodical service calls.</param><returns>The last HTTP response received from the server.</returns><remarks>
            This method will periodically call UpdateStatusAsync till HasCompleted is true, then return the final result of the operation.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls the server till the long-running operation completes.
            </summary><param name="pollingInterval">
            The interval between status requests to the server.
            The interval can change based on information returned from the server.
            For example, the server might communicate to the client that there is not reason to poll for status change sooner than some time.
            </param><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the periodical service calls.</param><returns>The last HTTP response received from the server.</returns><remarks>
            This method will periodically call UpdateStatusAsync till HasCompleted is true, then return the final result of the operation.
            </remarks>
        </member>
        <member name="T:Azure.Core.SequentialDelayStrategy">
            <summary>
            A delay strategy that uses a fixed sequence of delays with no jitter applied. This is used by management LROs.
            </summary>
        </member>
        <member name="T:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions">
            <summary> Extension methods to add <see cref="T:Azure.AI.Inference.ChatCompletionsClient" />, <see cref="T:Azure.AI.Inference.EmbeddingsClient" /> to client builder. </summary>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddChatCompletionsClient``1(``0,System.Uri,Azure.AzureKeyCredential)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.ChatCompletionsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddChatCompletionsClient``1(``0,System.Uri)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.ChatCompletionsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint"> Service host. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddEmbeddingsClient``1(``0,System.Uri,Azure.AzureKeyCredential)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.EmbeddingsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint"> Service host. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddEmbeddingsClient``1(``0,System.Uri)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.EmbeddingsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint"> Service host. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddChatCompletionsClient``2(``0,``1)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.ChatCompletionsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="configuration"> The configuration values. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIInferenceClientBuilderExtensions.AddEmbeddingsClient``2(``0,``1)">
            <summary> Registers a <see cref="T:Azure.AI.Inference.EmbeddingsClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="configuration"> The configuration values. </param>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute">
            <summary>
            Indicates that the specified method requires the ability to generate new code at runtime,
            for example through <see cref="N:System.Reflection" />.
            </summary>
            <remarks>
            This allows tools to understand which methods are unsafe to call when compiling ahead of time.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute" /> class
            with the specified message.
            </summary>
            <param name="message">
            A message that contains information about the usage of dynamic code.
            </param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.Message">
            <summary>
            Gets a message that contains information about the usage of dynamic code.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.Url">
            <summary>
            Gets or sets an optional URL that contains more information about the method,
            why it requires dynamic code, and what options a consumer has to deal with it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute">
            <summary>
            Indicates that the specified method requires dynamic access to code that is not referenced
            statically, for example through <see cref="N:System.Reflection" />.
            </summary>
            <remarks>
            This allows tools to understand which methods are unsafe to call when removing unreferenced
            code from an application.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute" /> class
            with the specified message.
            </summary>
            <param name="message">
            A message that contains information about the usage of unreferenced code.
            </param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.Message">
            <summary>
            Gets a message that contains information about the usage of unreferenced code.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.Url">
            <summary>
            Gets or sets an optional URL that contains more information about the method,
            why it requires unreferenced code, and what options a consumer has to deal with it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute">
            <summary>
            Suppresses reporting of a specific rule violation, allowing multiple suppressions on a
            single code artifact.
            </summary>
            <remarks>
            <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" /> is different than
            <see cref="T:System.Diagnostics.CodeAnalysis.SuppressMessageAttribute" /> in that it doesn't have a
            <see cref="T:System.Diagnostics.ConditionalAttribute" />. So it is always preserved in the compiled assembly.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" />
            class, specifying the category of the tool and the identifier for an analysis rule.
            </summary>
            <param name="category">The category for the attribute.</param>
            <param name="checkId">The identifier of the analysis rule the attribute applies to.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category">
            <summary>
            Gets the category identifying the classification of the attribute.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category" /> property describes the tool or tool analysis category
            for which a message suppression attribute applies.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.CheckId">
            <summary>
            Gets the identifier of the analysis tool rule to be suppressed.
            </summary>
            <remarks>
            Concatenated together, the <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category" /> and <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.CheckId" />
            properties form a unique check identifier.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Scope">
            <summary>
            Gets or sets the scope of the code that is relevant for the attribute.
            </summary>
            <remarks>
            The Scope property is an optional argument that specifies the metadata scope for which
            the attribute is relevant.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Target">
            <summary>
            Gets or sets a fully qualified path that represents the target of the attribute.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Target" /> property is an optional argument identifying the analysis target
            of the attribute. An example value is "System.IO.Stream.ctor():System.Void".
            Because it is fully qualified, it can be long, particularly for targets such as parameters.
            The analysis tool user interface should be capable of automatically formatting the parameter.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.MessageId">
            <summary>
            Gets or sets an optional argument expanding on exclusion criteria.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.MessageId" /> property is an optional argument that specifies additional
            exclusion where the literal metadata target is not sufficiently precise. For example,
            the <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" /> cannot be applied within a method,
            and it may be desirable to suppress a violation against a statement in the method that will
            give a rule violation, but not against all statements in the method.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Justification">
            <summary>
            Gets or sets the justification for suppressing the code analysis message.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute">
            <summary>
            States a dependency that one member has on another.
            </summary>
            <remarks>
            This can be used to inform tooling of a dependency that is otherwise not evident purely from
            metadata and IL, for example a member relied on via reflection.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on the same type as the consumer.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String,System.Type)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on a <see cref="T:System.Type" />.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
            <param name="type">The <see cref="T:System.Type" /> containing <paramref name="memberSignature" />.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on a type in an assembly.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
            <param name="typeName">The full name of the type containing the specified member.</param>
            <param name="assemblyName">The assembly name of the type containing the specified member.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes,System.Type)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified types of members on a <see cref="T:System.Type" />.
            </summary>
            <param name="memberTypes">The types of members depended on.</param>
            <param name="type">The <see cref="T:System.Type" /> containing the specified members.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified types of members on a type in an assembly.
            </summary>
            <param name="memberTypes">The types of members depended on.</param>
            <param name="typeName">The full name of the type containing the specified members.</param>
            <param name="assemblyName">The assembly name of the type containing the specified members.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature">
            <summary>
            Gets the signature of the member depended on.
            </summary>
            <remarks>
            Either <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature" /> must be a valid string or <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes" />
            must not equal <see cref="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None" />, but not both.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes">
            <summary>
            Gets the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes" /> which specifies the type
            of members depended on.
            </summary>
            <remarks>
            Either <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature" /> must be a valid string or <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes" />
            must not equal <see cref="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None" />, but not both.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type">
            <summary>
            Gets the <see cref="T:System.Type" /> containing the specified member.
            </summary>
            <remarks>
            If neither <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type" /> nor <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> are specified,
            the type of the consumer is assumed.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName">
            <summary>
            Gets the full name of the type containing the specified member.
            </summary>
            <remarks>
            If neither <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type" /> nor <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> are specified,
            the type of the consumer is assumed.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.AssemblyName">
            <summary>
            Gets the assembly name of the specified type.
            </summary>
            <remarks>
            <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.AssemblyName" /> is only valid when <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> is specified.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Condition">
            <summary>
            Gets or sets the condition in which the dependency is applicable, e.g. "DEBUG".
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute">
             <summary>
             Indicates that certain members on a specified <see cref="T:System.Type" /> are accessed dynamically,
             for example through <see cref="N:System.Reflection" />.
             </summary>
             <remarks>
             This allows tools to understand which members are being accessed during the execution
             of a program.
            
             This attribute is valid on members whose type is <see cref="T:System.Type" /> or <see cref="T:System.String" />.
            
             When this attribute is applied to a location of type <see cref="T:System.String" />, the assumption is
             that the string represents a fully qualified type name.
            
             When this attribute is applied to a class, interface, or struct, the members specified
             can be accessed dynamically on <see cref="T:System.Type" /> instances returned from calling
             <see cref="M:System.Object.GetType" /> on instances of that class, interface, or struct.
            
             If the attribute is applied to a method it's treated as a special case and it implies
             the attribute should be applied to the "this" parameter of the method. As such the attribute
             should only be used on instance methods of types assignable to System.Type (or string, but no methods
             will use it there).
             </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute" /> class
            with the specified member types.
            </summary>
            <param name="memberTypes">The types of members dynamically accessed.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute.MemberTypes">
            <summary>
            Gets the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes" /> which specifies the type
            of members dynamically accessed.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes">
             <summary>
             Specifies the types of members that are dynamically accessed.
            
             This enumeration has a <see cref="T:System.FlagsAttribute" /> attribute that allows a
             bitwise combination of its member values.
             </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None">
            <summary>
            Specifies no members.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicParameterlessConstructor">
            <summary>
            Specifies the default, parameterless public constructor.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicConstructors">
            <summary>
            Specifies all public constructors.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicConstructors">
            <summary>
            Specifies all non-public constructors.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicMethods">
            <summary>
            Specifies all public methods.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicMethods">
            <summary>
            Specifies all non-public methods.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicFields">
            <summary>
            Specifies all public fields.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicFields">
            <summary>
            Specifies all non-public fields.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicNestedTypes">
            <summary>
            Specifies all public nested types.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicNestedTypes">
            <summary>
            Specifies all non-public nested types.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicProperties">
            <summary>
            Specifies all public properties.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicProperties">
            <summary>
            Specifies all non-public properties.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicEvents">
            <summary>
            Specifies all public events.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicEvents">
            <summary>
            Specifies all non-public events.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.Interfaces">
            <summary>
            Specifies all interfaces implemented by the type.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.All">
            <summary>
            Specifies all members.
            </summary>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletions}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletions}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletions}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletions}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletions}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsOptions}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsOptions}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsOptions}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsOptions}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsOptions}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsToolCall}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsToolCall}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolCall}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolCall}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolCall}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsToolDefinition}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsToolDefinition}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolDefinition}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolDefinition}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsToolDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsToolDefinition}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageImageContentItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageImageContentItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageContentItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageContentItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageContentItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageImageUrl}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageImageUrl}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageUrl}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageUrl}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageImageUrl.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageImageUrl}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestAssistantMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestAssistantMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestAssistantMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestAssistantMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestAssistantMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestAssistantMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestUserMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestUserMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestUserMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestUserMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestUserMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestUserMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#FunctionCall}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#FunctionCall}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionCall}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionCall}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionCall.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionCall}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#FunctionDefinition}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#FunctionDefinition}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionDefinition}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionDefinition}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.FunctionDefinition.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#FunctionDefinition}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatChoiceUpdate}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatChoiceUpdate}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatChoiceUpdate}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatChoiceUpdate}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatChoiceUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatChoiceUpdate}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatCompletionsUpdate}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatCompletionsUpdate}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatCompletionsUpdate}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatCompletionsUpdate}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatCompletionsUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatCompletionsUpdate}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatResponseMessageUpdate}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatResponseMessageUpdate}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseMessageUpdate}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseMessageUpdate}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseMessageUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseMessageUpdate}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatChoice}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatChoice}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatChoice}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatChoice}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatChoice}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsNamedToolChoice}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsNamedToolChoice}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoice}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoice}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoice.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoice}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsNamedToolChoiceFunction}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsNamedToolChoiceFunction}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoiceFunction}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoiceFunction}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsNamedToolChoiceFunction.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsNamedToolChoiceFunction}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormatJSON}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormatJSON}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatJSON}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatJSON}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatJSON.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatJSON}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormatText}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormatText}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatText}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatText}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatCompletionsResponseFormatText.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormatText}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageContentItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageContentItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageTextContentItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageTextContentItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageTextContentItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageTextContentItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatMessageTextContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageTextContentItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestSystemMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestSystemMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestSystemMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestSystemMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestSystemMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestSystemMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestToolMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestToolMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestToolMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestToolMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatRequestToolMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestToolMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatResponseMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatResponseMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatResponseMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatResponseMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ChatResponseMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatResponseMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#CompleteRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#CompleteRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompleteRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompleteRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompleteRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompleteRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#CompletionsUsage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#CompletionsUsage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompletionsUsage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompletionsUsage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.CompletionsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#CompletionsUsage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsOptions}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsOptions}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsOptions}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsOptions}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsOptions.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsOptions}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsUsage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbeddingsUsage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsUsage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsUsage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbeddingsUsage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbeddingsUsage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbedRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#EmbedRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbedRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbedRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.EmbedRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#EmbedRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="P:Azure.AI.Inference.ChangeTrackingDictionary`2.System#Collections#Generic#IReadOnlyDictionary{TKey@TValue}#Keys">
            <summary>Gets an enumerable collection that contains the keys in the read-only dictionary.</summary><returns>An enumerable collection that contains the keys in the read-only dictionary.</returns>
        </member>
        <member name="P:Azure.AI.Inference.ChangeTrackingDictionary`2.System#Collections#Generic#IReadOnlyDictionary{TKey@TValue}#Values">
            <summary>Gets an enumerable collection that contains the values in the read-only dictionary.</summary><returns>An enumerable collection that contains the values in the read-only dictionary.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChangeTrackingDictionary`2.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ChangeTrackingList`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ModelInfo}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ModelInfo}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ModelInfo}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ModelInfo}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.ModelInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ModelInfo}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatResponseToolCallUpdate}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#StreamingChatResponseToolCallUpdate}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseToolCallUpdate}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseToolCallUpdate}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.StreamingChatResponseToolCallUpdate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#StreamingChatResponseToolCallUpdate}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatCompletionsResponseFormat.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatCompletionsResponseFormat}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageContentItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatMessageContentItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatMessageContentItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatMessageContentItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestMessage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Inference#ChatRequestMessage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Inference.UnknownChatRequestMessage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Inference#ChatRequestMessage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to consider when serializing and deserializing the model.</param><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Inference.StreamingResponse`1.System#Collections#Generic#IAsyncEnumerable{T}#GetAsyncEnumerator(System.Threading.CancellationToken)">
            <summary>Returns an enumerator that iterates asynchronously through the collection.</summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> that may be used to cancel the asynchronous iteration.</param><returns>An enumerator that can be used to iterate asynchronously through the collection.</returns>
        </member>
        <member name="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.System#Collections#Generic#IEnumerable{T}#GetEnumerator">
            <summary>Returns an enumerator that iterates through the collection.</summary><returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="P:Azure.Core.Pipeline.TaskExtensions.Enumerator`1.System#Collections#IEnumerator#Current">
            <summary>Gets the element in the collection at the current position of the enumerator.</summary><returns>The element in the collection at the current position of the enumerator.</returns>
        </member>
    </members>
</doc>
